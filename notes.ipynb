{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "446df8cd-5b4f-4b24-9925-35a670702372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.width = 150\n",
    "RANDOM_SEED = 696\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6b43438-2d70-4ab1-b330-b91dbef04ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('assets/WikiLarge_Train.csv')\n",
    "train_feats_df = pd.read_csv('assets/train_features_df.csv').rename({'Unnamed: 0': 'idx'}, axis=1).set_index('idx')\n",
    "score_feats_df = pd.read_csv('assets/score_features.csv').rename({'Unnamed: 0': 'idx'}, axis=1).set_index('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16cf39b7-a7f8-4a5e-a696-9fbcecd69533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 416768 entries, 0 to 416767\n",
      "Data columns (total 61 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   original_text             416768 non-null  object \n",
      " 1   label                     416768 non-null  int64  \n",
      " 2   sentence_word_count       416768 non-null  int64  \n",
      " 3   sentence_dc_word_count    416768 non-null  int64  \n",
      " 4   percent_dc_words          416768 non-null  float64\n",
      " 5   sentence_dc_stword_count  416768 non-null  int64  \n",
      " 6   percent_dc_stwords        416768 non-null  float64\n",
      " 7   syl_count                 416768 non-null  int64  \n",
      " 8   FK_Read_Ease              416768 non-null  float64\n",
      " 9   FK_Read_Grade             416768 non-null  float64\n",
      " 10  Dom_PoS_SUBTLEX           416768 non-null  object \n",
      " 11  AoA_NoMatch               416768 non-null  int64  \n",
      " 12  AoA_Freq_pm_median        408218 non-null  float64\n",
      " 13  AoA_Freq_pm_mean          408218 non-null  float64\n",
      " 14  AoA_Nletter_median        408234 non-null  float64\n",
      " 15  AoA_Nletter_mean          408234 non-null  float64\n",
      " 16  AoA_Nphon_median          408234 non-null  float64\n",
      " 17  AoA_Nphon_mean            408234 non-null  float64\n",
      " 18  AoA_Nsyll_median          408234 non-null  float64\n",
      " 19  AoA_Nsyll_mean            408234 non-null  float64\n",
      " 20  AoA_Pct_known_lem_median  408234 non-null  float64\n",
      " 21  AoA_Pct_known_lem_mean    408234 non-null  float64\n",
      " 22  AoA_Pct_known_median      404501 non-null  float64\n",
      " 23  AoA_Pct_known_mean        404501 non-null  float64\n",
      " 24  Conc_M__median            405197 non-null  float64\n",
      " 25  Conc_M__mean              405197 non-null  float64\n",
      " 26  Conc_SD_median            405197 non-null  float64\n",
      " 27  Conc_SD_mean              405197 non-null  float64\n",
      " 28  Conc_Uknown_median        405197 non-null  float64\n",
      " 29  Conc_Uknown_mean          405197 non-null  float64\n",
      " 30  Conc_Pct_known_median     405197 non-null  float64\n",
      " 31  Conc_Pct_known_mean       405197 non-null  float64\n",
      " 32  Conc_SUBTLEX_median       405197 non-null  float64\n",
      " 33  Conc_SUBTLEX_mean         405197 non-null  float64\n",
      " 34  Dom_PoS_SUBTLEX.1         416768 non-null  object \n",
      " 35  Dom_Pos                   416768 non-null  object \n",
      " 36  total_words               416768 non-null  int64  \n",
      " 37  long_words                416768 non-null  int64  \n",
      " 38  total_sentences           416768 non-null  int64  \n",
      " 39  total_characters          416768 non-null  int64  \n",
      " 40  syl_list                  416768 non-null  object \n",
      " 41  total_syllables           416768 non-null  int64  \n",
      " 42  total_polysyllables       416768 non-null  int64  \n",
      " 43  total_unique_words        416768 non-null  int64  \n",
      " 44  gfi                       416768 non-null  float64\n",
      " 45  fre                       416479 non-null  float64\n",
      " 46  fkgl                      416479 non-null  float64\n",
      " 47  ari                       416479 non-null  float64\n",
      " 48  smog                      416768 non-null  float64\n",
      " 49  ttr                       416479 non-null  float64\n",
      " 50  5gram_msttr               416479 non-null  float64\n",
      " 51  3gram_msttr               416479 non-null  float64\n",
      " 52  2gram_msttr               416479 non-null  float64\n",
      " 53  rttr                      416479 non-null  float64\n",
      " 54  cttr                      416479 non-null  float64\n",
      " 55  5gram_mattr               416479 non-null  float64\n",
      " 56  len_ngram_mattr           416479 non-null  float64\n",
      " 57  5gram_ma_syl              415744 non-null  float64\n",
      " 58  len_ngram_ma_syl          415744 non-null  float64\n",
      " 59  syl_mean                  415744 non-null  float64\n",
      " 60  syl_std                   415744 non-null  float64\n",
      "dtypes: float64(43), int64(13), object(5)\n",
      "memory usage: 194.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = train_df.join(train_feats_df).join(score_feats_df)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cf96c15-4ce6-4f98-8915-b0bb8eeb1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df, test_df = np.split(df.sample(frac=1, random_state= RANDOM_SEED), \n",
    "                       [int(.8*len(df)), int(.9*len(df))], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a206f35-a090-46b7-8f93-79e8e119d544",
   "metadata": {},
   "source": [
    "## tfidf dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abab094c-10f4-49d8-8649-3c1ea07cb29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\",     \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers',     'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which',     'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been',     'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but',     'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against',     'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up',     'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when',     'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor',     'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\",     'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn',    \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\",     'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn',     \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'rrb', 'lrb']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b51696b-a6d4-46e4-907c-1ff214f880b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=25, max_df= .9, strip_accents='ascii',  analyzer='word', ngram_range=(1,3), lowercase=False, stop_words=custom_stop_words)\n",
    "\n",
    "# Transform data and labels\n",
    "X_train = vectorizer.fit_transform(train_df.original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8c5d686-090c-4a3a-ae0b-6c25302d684f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333414, 27095)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df8ea0fb-48fc-4492-b436-a60c7fb14722",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_size = int(X_train.shape[0] * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2550659b-6b8c-471c-ab74-bddb60f982a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33341,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = np.random.choice(X_train.shape[0], size=samp_size,replace=False)\n",
    "samp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87268b07-8e4c-477c-b0d7-ee61978d2024",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_samp = X_train[samp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81632132-20d3-4ac6-9e9c-4f2d650da7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(n_neighbors=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(n_neighbors=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors(n_neighbors=1)\n",
    "\n",
    "neigh.fit(X_train_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da94fe6c-d6c1-4afa-b678-ec4c71a87616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.median(neigh.kneighbors(X_train_samp)[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a92bedf-a134-43f0-b5d1-ac627a06c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# metrics.silhouette_score(df, df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbc25c7d-ce0e-442c-bb8f-3a950b956b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=2, random_state=RANDOM_SEED).fit(X_train)\n",
    "data2D = svd.transform(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94cc57de-c17e-462f-83d2-87338118875d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00973815, -0.00166164],\n",
       "       [ 0.01730446,  0.03953571],\n",
       "       [ 0.10813404, -0.02413826],\n",
       "       ...,\n",
       "       [ 0.16321413, -0.01593165],\n",
       "       [ 0.        ,  0.        ],\n",
       "       [ 0.09643596,  0.35162675]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b479498-df2f-40f5-8264-c181449c85ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8781081744144819"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2D.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b290ef1-cb45-4a4c-9597-49557eae8711",
   "metadata": {},
   "source": [
    "## Classify using sent2vec by SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bb799b3-9e2f-4437-b8b4-fd6278873644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8966270b-819e-4a4c-9044-49b194ab90fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736afd6c1e8c4fdd904fcd3706221487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)001fa/.gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e970c1b80b46178c0b64788b5097bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19a3299120343549eb36758a546aaf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)3bbb8001fa/README.md:   0%|          | 0.00/3.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8785b49b29349d1af1800695b70833a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)bb8001fa/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe1bee6aec04abb921f4af821701692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bf98f164de4f47ab54d075bf999dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba18b1cb229c4f77a437427399844e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788f60e282b0419f97fa105e212fe3b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c326850110e94734853696c8211d2a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)001fa/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9106e681dd694b779510a5c0d603929e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec726de883b41b6bd263c2b92927034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)3bbb8001fa/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a2dcd73575460e9332736126105000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b8001fa/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab2ff9cb-c002-4854-ac6e-bdc4424e7641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bcaf429-399f-4647-b2f4-d0138a9d59b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf9aaaccd3b46ae8e803aa3ef815829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=52096), Label(value='0 / 52096')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0e9762b4334d10ad738ef6fdb7294f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=52096), Label(value='0 / 52096')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split_pat = re.compile(r'\\b\\s+\\b')\n",
    "split_pat = re.compile(r'\\w+')\n",
    "\n",
    "df['og_split'] = df['original_text'].parallel_apply(lambda x: re.findall(split_pat, x))\n",
    "df['cleaned_text'] = df['og_split'].parallel_apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0de73a33-8362-4e9c-ad8a-4a74d8921953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 10 years to run\n",
    "# df['sent_vec'] = df['cleaned_text'].apply(lambda x: model.encode([x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a2b94ff-a938-4666-b8ba-4130297c8b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also takes 10 years to run\n",
    "# df['sent_vec'].to_csv('assets/sent_vec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6fdd7e67-55ac-4653-9f16-7f320cf9c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a798dc59-07a6-4e38-9b34-be19567041ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sent_vec'] = df['sent_vec'].apply(np.ndarray.flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bbd69ff4-0751-4b9d-af5b-6528a2426523",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vec_np_array = np.array(df['sent_vec'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0fa8ef8f-fc38-440c-9572-a54472f5dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('sent_vec_np_array.csv', sent_vec_np_array, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5a7c5a1-cb9a-4656-9cd9-7695294f30dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_sent_vec_np_array = sent_vec_np_array / np.linalg.norm(sent_vec_np_array, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c2ddd85d-e668-47c6-b264-5e84908b44f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of obs clustered 245827\n",
      "number of clusters 13592\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/util.py\n",
    "from sentence_transformers import util\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "normed_sent_vec_torch_array = torch.from_numpy(normed_sent_vec_np_array)\n",
    "\n",
    "cls = util.community_detection(normed_sent_vec_torch_array, min_community_size=8, threshold=0.60)\n",
    "\n",
    "cluster_sizes = [len(cluster) for cluster in cls]\n",
    "print(f'number of obs clustered {sum(cluster_sizes)}')\n",
    "print(f'number of clusters {len(cluster_sizes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "769a595e-91d9-499e-a07a-821d1ac3243f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416768"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_vec_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ff762719-988c-4e27-a430-22e73a962830",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_dict = {n:-1 for n in range(len(sent_vec_np_array))}\n",
    "\n",
    "for i, cluster in enumerate(cls):\n",
    "    for n in cluster:\n",
    "        if clust_dict.get(n) == -1:\n",
    "            clust_dict[n] = i\n",
    "        else:\n",
    "            print('collision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ca803186-aea7-4733-8cf1-14364e261f65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(clust_dict, orient='index').rename({0:'sent_vec_class'}, axis=1).to_csv('assets/sent_vec_class.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca33953-9159-4343-92be-ea3a35983146",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2e62f8d-74d0-4a25-913f-eece5899df40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vec_np_array = np.loadtxt('sent_vec_np_array.csv', delimiter=',', dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d9c3bd6-b1fa-426c-af31-98e351151f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14739437, -0.14400522,  0.30520254, ...,  0.186005  ,\n",
       "         0.13216972,  0.0271847 ],\n",
       "       [-0.3423788 ,  0.64353764,  0.09641959, ...,  0.03769291,\n",
       "         0.25474536,  0.45148695],\n",
       "       [ 0.11564089,  0.34492534, -0.12513059, ...,  0.12841401,\n",
       "        -0.02132292, -0.15871231],\n",
       "       ...,\n",
       "       [ 0.2169555 ,  0.92392933, -0.21317533, ...,  0.4750323 ,\n",
       "        -0.06613453,  0.3433581 ],\n",
       "       [ 0.03890196, -0.05102391, -0.30264756, ...,  0.11241401,\n",
       "         0.14131893,  0.16626678],\n",
       "       [-0.05067663, -1.06192613, -0.72202456, ...,  0.11790838,\n",
       "         0.18318109, -0.1881723 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_vec_np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb1d23bf-5bed-43b0-899e-9da660794d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['col_vecs'] = sent_vec_np_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d934057-4ad0-45c6-bf06-fdee350d06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('assets/WikiLarge_Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b2707d9-bcd7-42d0-b88d-ca5473dfffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.join(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51068af-d258-4344-8172-b1e4145b4cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>col_vecs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[-0.14739437401294708, -0.14400522410869598, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-0.34237879514694214, 0.6435376405715942, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.11564088612794876, 0.3449253439903259, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.19127874076366425, 0.21434128284454346, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.25611141324043274, 0.002085210755467415, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416763</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.2092808485031128, 0.1518959254026413, 0.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416764</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.21063463389873505, -0.08211549371480942, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416765</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.2169554978609085, 0.9239293336868286, -0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416766</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.03890196233987808, -0.05102391168475151, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416767</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0506766252219677, -1.0619261264801025, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416768 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                           col_vecs\n",
       "0           1  [-0.14739437401294708, -0.14400522410869598, 0...\n",
       "1           1  [-0.34237879514694214, 0.6435376405715942, 0.0...\n",
       "2           1  [0.11564088612794876, 0.3449253439903259, -0.1...\n",
       "3           1  [0.19127874076366425, 0.21434128284454346, -0....\n",
       "4           1  [0.25611141324043274, 0.002085210755467415, -0...\n",
       "...       ...                                                ...\n",
       "416763      0  [-0.2092808485031128, 0.1518959254026413, 0.27...\n",
       "416764      0  [-0.21063463389873505, -0.08211549371480942, -...\n",
       "416765      0  [0.2169554978609085, 0.9239293336868286, -0.21...\n",
       "416766      0  [0.03890196233987808, -0.05102391168475151, -0...\n",
       "416767      0  [-0.0506766252219677, -1.0619261264801025, -0....\n",
       "\n",
       "[416768 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('original_text', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09c2a5bd-6d96-4a2d-8bb1-78d57268ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df, test_df = np.split(df.sample(frac=1, random_state= RANDOM_SEED), \n",
    "                       [int(.8*len(df)), int(.9*len(df))], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c63edfb-97d9-43ee-8ed9-82ee078dc697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18d6910b-2f95-4707-b458-80cc383eaea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6e6227ce324f71b484a1c528cd7561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=41677), Label(value='0 / 41677')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046ffbf25e8442d9bcbd877b6fae6dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=41677), Label(value='0 / 41677')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dedbf3fcad354f97932c2821b952ae45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=41677), Label(value='0 / 41677')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3058dd3cd3a84a55ae549f8ef31cc3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=41677), Label(value='0 / 41677')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7823554d6b84ccfa8cc69c3c476a56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=5210), Label(value='0 / 5210'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fdbe1bde814842a0291a4347aa350e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=5210), Label(value='0 / 5210'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train = train_df['label'].parallel_apply(lambda x: np.array(x))\n",
    "X_train = train_df['col_vecs'].parallel_apply(lambda x: np.array(x))\n",
    "y_dev = train_df['label'].parallel_apply(lambda x: np.array(x))\n",
    "X_dev = train_df['col_vecs'].parallel_apply(lambda x: np.array(x))\n",
    "y_test = test_df['label'].parallel_apply(lambda x: np.array(x))\n",
    "X_test = test_df['col_vecs'].parallel_apply(lambda x: np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3cfaa76-4d2f-4043-ada7-31b6ad4822a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = np.concatenate(X_train.values).reshape(len(X_train.index), 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "686e77d5-4dfa-47ab-ad5c-aea686175a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_np = np.concatenate(X_test.values).reshape(len(X_test.index), 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebfae97d-5e8c-4daa-ba09-02d929bcfe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;baggingclassifier&#x27;,\n",
       "                 BaggingClassifier(estimator=LinearSVC(max_iter=2000),\n",
       "                                   n_estimators=20, random_state=696))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;baggingclassifier&#x27;,\n",
       "                 BaggingClassifier(estimator=LinearSVC(max_iter=2000),\n",
       "                                   n_estimators=20, random_state=696))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">baggingclassifier: BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(estimator=LinearSVC(max_iter=2000), n_estimators=20,\n",
       "                  random_state=696)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(max_iter=2000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(max_iter=2000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('baggingclassifier',\n",
       "                 BaggingClassifier(estimator=LinearSVC(max_iter=2000),\n",
       "                                   n_estimators=20, random_state=696))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "svc_clf = make_pipeline(StandardScaler(), BaggingClassifier(estimator=LinearSVC(max_iter=2000), n_estimators=20, random_state=RANDOM_SEED))\n",
    "svc_clf.fit(X_train_np, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "501c6525-5257-46f7-bf9b-59406c7e08d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6324351560812919"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf.score(X_test_np, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed123282-6905-47ab-9817-d8cf63a6b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "456aae46-ac19-422b-9f26-ea539b5d8c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "\n",
    "clusterable_embedding = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.0,\n",
    "    n_components=10,\n",
    "    random_state=RANDOM_SEED\n",
    ").fit_transform(sent_vec_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b0c03b2-d37c-4d18-9c00-054e95ded922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "\n",
    "labels = hdbscan.HDBSCAN(\n",
    "    min_samples=100,\n",
    "    min_cluster_size=500\n",
    ").fit_predict(clusterable_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ee9fc3a-8197-47f9-8284-5f8d865194c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({67: 2068,\n",
       "         50: 4423,\n",
       "         49: 709,\n",
       "         -1: 215502,\n",
       "         15: 3265,\n",
       "         70: 975,\n",
       "         7: 2364,\n",
       "         41: 1878,\n",
       "         29: 2578,\n",
       "         32: 6772,\n",
       "         31: 29698,\n",
       "         72: 2083,\n",
       "         37: 8580,\n",
       "         81: 629,\n",
       "         63: 1293,\n",
       "         76: 5120,\n",
       "         20: 5567,\n",
       "         13: 4290,\n",
       "         75: 1238,\n",
       "         39: 2761,\n",
       "         52: 5419,\n",
       "         44: 1176,\n",
       "         53: 540,\n",
       "         16: 1737,\n",
       "         59: 733,\n",
       "         19: 3225,\n",
       "         46: 3057,\n",
       "         62: 1111,\n",
       "         33: 1625,\n",
       "         17: 1734,\n",
       "         78: 13001,\n",
       "         25: 1653,\n",
       "         26: 1675,\n",
       "         60: 1962,\n",
       "         66: 8711,\n",
       "         57: 3152,\n",
       "         73: 1522,\n",
       "         54: 1526,\n",
       "         27: 619,\n",
       "         35: 526,\n",
       "         10: 3456,\n",
       "         18: 1097,\n",
       "         12: 828,\n",
       "         28: 4320,\n",
       "         2: 820,\n",
       "         9: 1555,\n",
       "         51: 808,\n",
       "         40: 3153,\n",
       "         56: 1928,\n",
       "         58: 2490,\n",
       "         64: 3081,\n",
       "         61: 1323,\n",
       "         22: 1698,\n",
       "         36: 1535,\n",
       "         65: 1471,\n",
       "         80: 716,\n",
       "         24: 2018,\n",
       "         47: 1095,\n",
       "         4: 536,\n",
       "         5: 669,\n",
       "         14: 764,\n",
       "         71: 1245,\n",
       "         21: 586,\n",
       "         6: 2330,\n",
       "         74: 587,\n",
       "         48: 1609,\n",
       "         79: 4509,\n",
       "         77: 855,\n",
       "         30: 721,\n",
       "         45: 2375,\n",
       "         43: 565,\n",
       "         55: 1699,\n",
       "         23: 646,\n",
       "         68: 698,\n",
       "         42: 566,\n",
       "         8: 631,\n",
       "         38: 544,\n",
       "         69: 797,\n",
       "         0: 1238,\n",
       "         11: 625,\n",
       "         34: 727,\n",
       "         3: 685,\n",
       "         1: 672})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0812855e-4251-497c-a8be-5bb39be1c41c",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0367eb15-a8f5-4d68-95e5-d2c50d9db0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.3, min_samples=2)\n",
    "cls = dbscan.fit_predict(data2D)\n",
    "print(f'Cluster membership values: \\n{cls}')\n",
    "Counter(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45898ba6-d7d7-4bf3-a668-642dfa929896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d31cdd88-2d28-4bb1-bcbc-5b1effa8d598",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "122742ce-c639-4951-be48-8c800a8cde69",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_a_feature_list = ['original_text', 'label', 'syl_list', 'Dom_PoS_SUBTLEX.1', 'Dom_Pos', 'Dom_PoS_SUBTLEX', '']\n",
    "feats_list = [x for x in df.columns.tolist() if x not in not_a_feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95d9c1c5-67c7-4d58-815a-9623e76a7eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[feats_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d101e97b-8937-4c9d-b5c3-c44ff190f688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_word_count            0\n",
       "sentence_dc_word_count         0\n",
       "percent_dc_words               0\n",
       "sentence_dc_stword_count       0\n",
       "percent_dc_stwords             0\n",
       "syl_count                      0\n",
       "FK_Read_Ease                   0\n",
       "FK_Read_Grade                  0\n",
       "AoA_NoMatch                    0\n",
       "AoA_Freq_pm_median          6852\n",
       "AoA_Freq_pm_mean            6852\n",
       "AoA_Nletter_median          6839\n",
       "AoA_Nletter_mean            6839\n",
       "AoA_Nphon_median            6839\n",
       "AoA_Nphon_mean              6839\n",
       "AoA_Nsyll_median            6839\n",
       "AoA_Nsyll_mean              6839\n",
       "AoA_Pct_known_lem_median    6839\n",
       "AoA_Pct_known_lem_mean      6839\n",
       "AoA_Pct_known_median        9807\n",
       "AoA_Pct_known_mean          9807\n",
       "Conc_M__median              9244\n",
       "Conc_M__mean                9244\n",
       "Conc_SD_median              9244\n",
       "Conc_SD_mean                9244\n",
       "Conc_Uknown_median          9244\n",
       "Conc_Uknown_mean            9244\n",
       "Conc_Pct_known_median       9244\n",
       "Conc_Pct_known_mean         9244\n",
       "Conc_SUBTLEX_median         9244\n",
       "Conc_SUBTLEX_mean           9244\n",
       "total_words                    0\n",
       "long_words                     0\n",
       "total_sentences                0\n",
       "total_characters               0\n",
       "total_syllables                0\n",
       "total_polysyllables            0\n",
       "total_unique_words             0\n",
       "gfi                            0\n",
       "fre                          238\n",
       "fkgl                         238\n",
       "ari                          238\n",
       "smog                           0\n",
       "ttr                          238\n",
       "5gram_msttr                  238\n",
       "3gram_msttr                  238\n",
       "2gram_msttr                  238\n",
       "rttr                         238\n",
       "cttr                         238\n",
       "5gram_mattr                  238\n",
       "len_ngram_mattr              238\n",
       "5gram_ma_syl                 816\n",
       "len_ngram_ma_syl             816\n",
       "syl_mean                     816\n",
       "syl_std                      816\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e7a5bf-a73d-46dc-b666-db59ba12a742",
   "metadata": {},
   "source": [
    "How to impute?\n",
    "- We could drop nans\n",
    "- Could impute with column mean\n",
    "- Could use sklearn imputer with rfregressor\n",
    "- Need to inspect rows with nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8b9be13-77ad-4d6d-8eb6-9cc2ac7af28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_words_mask = X['sentence_word_count']==0\n",
    "X.loc[zero_words_mask] = X.loc[zero_words_mask].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1888d6c-4c9f-4b74-9894-138dba8879d6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_word_count            0\n",
       "sentence_dc_word_count         0\n",
       "percent_dc_words               0\n",
       "sentence_dc_stword_count       0\n",
       "percent_dc_stwords             0\n",
       "syl_count                      0\n",
       "FK_Read_Ease                   0\n",
       "FK_Read_Grade                  0\n",
       "AoA_NoMatch                    0\n",
       "AoA_Freq_pm_median          6614\n",
       "AoA_Freq_pm_mean            6614\n",
       "AoA_Nletter_median          6601\n",
       "AoA_Nletter_mean            6601\n",
       "AoA_Nphon_median            6601\n",
       "AoA_Nphon_mean              6601\n",
       "AoA_Nsyll_median            6601\n",
       "AoA_Nsyll_mean              6601\n",
       "AoA_Pct_known_lem_median    6601\n",
       "AoA_Pct_known_lem_mean      6601\n",
       "AoA_Pct_known_median        9569\n",
       "AoA_Pct_known_mean          9569\n",
       "Conc_M__median              9006\n",
       "Conc_M__mean                9006\n",
       "Conc_SD_median              9006\n",
       "Conc_SD_mean                9006\n",
       "Conc_Uknown_median          9006\n",
       "Conc_Uknown_mean            9006\n",
       "Conc_Pct_known_median       9006\n",
       "Conc_Pct_known_mean         9006\n",
       "Conc_SUBTLEX_median         9006\n",
       "Conc_SUBTLEX_mean           9006\n",
       "total_words                    0\n",
       "long_words                     0\n",
       "total_sentences                0\n",
       "total_characters               0\n",
       "total_syllables                0\n",
       "total_polysyllables            0\n",
       "total_unique_words             0\n",
       "gfi                            0\n",
       "fre                            0\n",
       "fkgl                           0\n",
       "ari                            0\n",
       "smog                           0\n",
       "ttr                            0\n",
       "5gram_msttr                    0\n",
       "3gram_msttr                    0\n",
       "2gram_msttr                    0\n",
       "rttr                           0\n",
       "cttr                           0\n",
       "5gram_mattr                    0\n",
       "len_ngram_mattr                0\n",
       "5gram_ma_syl                 578\n",
       "len_ngram_ma_syl             578\n",
       "syl_mean                     578\n",
       "syl_std                      578\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "955a3065-762a-4ecc-9891-623bbe56397e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[19.        , 13.        ,  0.68      , ...,  1.37312922,\n",
       "         1.36842105,  0.48237639],\n",
       "       [10.        ,  4.        ,  0.4       , ...,  2.17638889,\n",
       "         1.8       ,  0.74833148],\n",
       "       [51.        , 29.        ,  0.57      , ...,  1.71411184,\n",
       "         1.57142857,  0.82065181],\n",
       "       ...,\n",
       "       [22.        , 16.        ,  0.73      , ...,  1.30747518,\n",
       "         1.15789474,  0.36464228],\n",
       "       [ 0.        ,  0.        , -1.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [17.        , 10.        ,  0.59      , ...,  1.42713855,\n",
       "         1.41176471,  0.69102001]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imp = IterativeImputer(max_iter=10, random_state=RANDOM_SEED)\n",
    "\n",
    "imp.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d1ab105-dff2-47e8-bdcd-f053bae063a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IterativeImputer(random_state=696)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IterativeImputer</label><div class=\"sk-toggleable__content\"><pre>IterativeImputer(random_state=696)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "IterativeImputer(random_state=696)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d39d7020-d445-4f9e-9bd9-81eaa5dbdb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imp = imp.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a379dc4-0271-4778-b056-f602148c8f03",
   "metadata": {},
   "source": [
    "## Get DBSCAN Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3d4c192b-d0b6-43cc-b059-30b1c1977164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(n_neighbors=3)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors(n_neighbors=3)\n",
    "samp = X_imp.sample(frac=0.1, random_state=RANDOM_SEED)\n",
    "\n",
    "neigh.fit(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "89b392b3-be8e-44ee-ae56-011543ccbf14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544.9467059789703"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(neigh.kneighbors(samp)[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd6f588-e023-498f-b90f-61f73daa2691",
   "metadata": {},
   "source": [
    "## Do DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c5f7dd2b-ab1d-46be-a8ac-1660d581648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "351b9b5b-4386-413d-8377-f0c7d51662de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster membership values: \n",
      "[    0     1     0 ... 17609     0     6]\n"
     ]
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps=1000, min_samples=2)\n",
    "cls = dbscan.fit_predict(X_imp)\n",
    "print(f'Cluster membership values: \\n{cls}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "66392adb-29c2-4cce-bb5e-98ffcedc8dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 144359,\n",
       "         1: 80,\n",
       "         2: 9555,\n",
       "         3: 39,\n",
       "         4: 2,\n",
       "         -1: 38631,\n",
       "         5: 855,\n",
       "         6: 10583,\n",
       "         7: 985,\n",
       "         8: 3266,\n",
       "         9: 4428,\n",
       "         10: 2,\n",
       "         11: 4,\n",
       "         12: 10,\n",
       "         13: 2844,\n",
       "         14: 148,\n",
       "         15: 3,\n",
       "         16: 6,\n",
       "         17: 2,\n",
       "         18: 50,\n",
       "         19: 3,\n",
       "         20: 5,\n",
       "         21: 2,\n",
       "         22: 64,\n",
       "         23: 350,\n",
       "         24: 11,\n",
       "         25: 4,\n",
       "         26: 341,\n",
       "         27: 2,\n",
       "         28: 2,\n",
       "         29: 7,\n",
       "         30: 3,\n",
       "         31: 20,\n",
       "         32: 2,\n",
       "         33: 18,\n",
       "         34: 111,\n",
       "         35: 5,\n",
       "         36: 2,\n",
       "         37: 4603,\n",
       "         38: 2,\n",
       "         39: 29,\n",
       "         40: 2,\n",
       "         41: 17,\n",
       "         42: 43,\n",
       "         43: 13,\n",
       "         44: 2,\n",
       "         45: 65,\n",
       "         46: 94,\n",
       "         47: 10,\n",
       "         48: 2,\n",
       "         49: 57,\n",
       "         50: 1153,\n",
       "         51: 40,\n",
       "         52: 103,\n",
       "         53: 4,\n",
       "         54: 5,\n",
       "         55: 81,\n",
       "         56: 2,\n",
       "         57: 110,\n",
       "         58: 92,\n",
       "         59: 117,\n",
       "         60: 3,\n",
       "         61: 142,\n",
       "         62: 71,\n",
       "         63: 7,\n",
       "         64: 96,\n",
       "         65: 4,\n",
       "         66: 70,\n",
       "         67: 3,\n",
       "         68: 2,\n",
       "         69: 11,\n",
       "         70: 768,\n",
       "         71: 2,\n",
       "         72: 4,\n",
       "         73: 22,\n",
       "         74: 6,\n",
       "         75: 4,\n",
       "         76: 49,\n",
       "         77: 494,\n",
       "         78: 2,\n",
       "         79: 28,\n",
       "         80: 5,\n",
       "         81: 399,\n",
       "         82: 2,\n",
       "         83: 2,\n",
       "         84: 9,\n",
       "         85: 2,\n",
       "         86: 41,\n",
       "         87: 99,\n",
       "         88: 3,\n",
       "         89: 10,\n",
       "         90: 24,\n",
       "         91: 44,\n",
       "         92: 2,\n",
       "         93: 16,\n",
       "         94: 51,\n",
       "         95: 10,\n",
       "         96: 2,\n",
       "         97: 2,\n",
       "         98: 5,\n",
       "         99: 2,\n",
       "         100: 37,\n",
       "         101: 84,\n",
       "         102: 7,\n",
       "         103: 3,\n",
       "         104: 2,\n",
       "         105: 3,\n",
       "         106: 3,\n",
       "         107: 2,\n",
       "         108: 2,\n",
       "         109: 2,\n",
       "         110: 9,\n",
       "         111: 76,\n",
       "         112: 14,\n",
       "         113: 2,\n",
       "         114: 43,\n",
       "         115: 2,\n",
       "         116: 25,\n",
       "         117: 11,\n",
       "         118: 377,\n",
       "         119: 9,\n",
       "         120: 3,\n",
       "         121: 2,\n",
       "         122: 8,\n",
       "         123: 59,\n",
       "         124: 16,\n",
       "         125: 4,\n",
       "         126: 32,\n",
       "         127: 5,\n",
       "         128: 2,\n",
       "         129: 9,\n",
       "         130: 6,\n",
       "         131: 7,\n",
       "         132: 2,\n",
       "         133: 3,\n",
       "         134: 15,\n",
       "         135: 147,\n",
       "         136: 4,\n",
       "         137: 2,\n",
       "         138: 94,\n",
       "         139: 215,\n",
       "         140: 1428,\n",
       "         141: 8,\n",
       "         142: 3,\n",
       "         143: 4,\n",
       "         144: 4,\n",
       "         145: 8,\n",
       "         146: 2,\n",
       "         147: 6,\n",
       "         148: 113,\n",
       "         149: 28,\n",
       "         150: 4,\n",
       "         151: 8,\n",
       "         152: 3,\n",
       "         153: 41,\n",
       "         154: 13,\n",
       "         155: 67,\n",
       "         156: 2173,\n",
       "         157: 3,\n",
       "         158: 2,\n",
       "         159: 4,\n",
       "         160: 303,\n",
       "         161: 9,\n",
       "         162: 89,\n",
       "         163: 10,\n",
       "         164: 2,\n",
       "         165: 45,\n",
       "         166: 5,\n",
       "         167: 4,\n",
       "         168: 39,\n",
       "         169: 4,\n",
       "         170: 31,\n",
       "         171: 7,\n",
       "         172: 7,\n",
       "         173: 2,\n",
       "         174: 2,\n",
       "         175: 4,\n",
       "         176: 130,\n",
       "         177: 352,\n",
       "         178: 3,\n",
       "         179: 2,\n",
       "         180: 4,\n",
       "         181: 160,\n",
       "         182: 12,\n",
       "         183: 3,\n",
       "         184: 51,\n",
       "         185: 11,\n",
       "         186: 88,\n",
       "         187: 76,\n",
       "         188: 2,\n",
       "         189: 11,\n",
       "         190: 25,\n",
       "         191: 5,\n",
       "         192: 17,\n",
       "         193: 3,\n",
       "         194: 28,\n",
       "         195: 6,\n",
       "         196: 2,\n",
       "         197: 19,\n",
       "         198: 84,\n",
       "         199: 99,\n",
       "         200: 6,\n",
       "         201: 51,\n",
       "         202: 22,\n",
       "         203: 23,\n",
       "         204: 3,\n",
       "         205: 2,\n",
       "         206: 4,\n",
       "         207: 221,\n",
       "         208: 2,\n",
       "         209: 3,\n",
       "         210: 2,\n",
       "         211: 205,\n",
       "         212: 3,\n",
       "         213: 119,\n",
       "         214: 8,\n",
       "         215: 182,\n",
       "         216: 2,\n",
       "         217: 244,\n",
       "         218: 19,\n",
       "         219: 2,\n",
       "         220: 2,\n",
       "         221: 2,\n",
       "         222: 4,\n",
       "         223: 5,\n",
       "         224: 44,\n",
       "         225: 5,\n",
       "         226: 6,\n",
       "         227: 20,\n",
       "         228: 167,\n",
       "         229: 3,\n",
       "         230: 2,\n",
       "         231: 6,\n",
       "         232: 3,\n",
       "         233: 62,\n",
       "         234: 42,\n",
       "         235: 10,\n",
       "         236: 65,\n",
       "         237: 32,\n",
       "         238: 2,\n",
       "         239: 5,\n",
       "         240: 2,\n",
       "         241: 2,\n",
       "         242: 11,\n",
       "         243: 145,\n",
       "         244: 32,\n",
       "         245: 4,\n",
       "         246: 58,\n",
       "         247: 37,\n",
       "         248: 48,\n",
       "         249: 2,\n",
       "         250: 54,\n",
       "         251: 16,\n",
       "         252: 2,\n",
       "         253: 2,\n",
       "         254: 7,\n",
       "         255: 390,\n",
       "         256: 33,\n",
       "         257: 9,\n",
       "         258: 6,\n",
       "         259: 30,\n",
       "         260: 30,\n",
       "         261: 43,\n",
       "         262: 259,\n",
       "         263: 3,\n",
       "         264: 20,\n",
       "         265: 8,\n",
       "         266: 7,\n",
       "         267: 3,\n",
       "         268: 2,\n",
       "         269: 2,\n",
       "         270: 27,\n",
       "         271: 2,\n",
       "         272: 38,\n",
       "         273: 62,\n",
       "         274: 5,\n",
       "         275: 2,\n",
       "         276: 3,\n",
       "         277: 4,\n",
       "         278: 12,\n",
       "         279: 3,\n",
       "         280: 2,\n",
       "         281: 53,\n",
       "         282: 16,\n",
       "         283: 5,\n",
       "         284: 5,\n",
       "         285: 7,\n",
       "         286: 3,\n",
       "         287: 589,\n",
       "         288: 2,\n",
       "         289: 2,\n",
       "         290: 15,\n",
       "         291: 7,\n",
       "         292: 74,\n",
       "         293: 9,\n",
       "         294: 2,\n",
       "         295: 28,\n",
       "         296: 6,\n",
       "         297: 41,\n",
       "         298: 2,\n",
       "         299: 6,\n",
       "         300: 2,\n",
       "         301: 2,\n",
       "         302: 2,\n",
       "         303: 2,\n",
       "         304: 22,\n",
       "         305: 7,\n",
       "         306: 3,\n",
       "         307: 64,\n",
       "         308: 6,\n",
       "         309: 2,\n",
       "         310: 7,\n",
       "         311: 2,\n",
       "         312: 2,\n",
       "         313: 134,\n",
       "         314: 52,\n",
       "         315: 67,\n",
       "         316: 9,\n",
       "         317: 284,\n",
       "         318: 174,\n",
       "         319: 27,\n",
       "         320: 10,\n",
       "         321: 3,\n",
       "         322: 7,\n",
       "         323: 2,\n",
       "         324: 86,\n",
       "         325: 2,\n",
       "         326: 5,\n",
       "         327: 22,\n",
       "         328: 32,\n",
       "         329: 2,\n",
       "         330: 6,\n",
       "         331: 16,\n",
       "         332: 2,\n",
       "         333: 85,\n",
       "         334: 4,\n",
       "         335: 3,\n",
       "         336: 5,\n",
       "         337: 6,\n",
       "         338: 8,\n",
       "         339: 38,\n",
       "         340: 2,\n",
       "         341: 76,\n",
       "         342: 6,\n",
       "         343: 3,\n",
       "         344: 2,\n",
       "         345: 6,\n",
       "         346: 6,\n",
       "         347: 20,\n",
       "         348: 132,\n",
       "         349: 2,\n",
       "         350: 3,\n",
       "         351: 2,\n",
       "         352: 2,\n",
       "         353: 6,\n",
       "         354: 2,\n",
       "         355: 8,\n",
       "         356: 2,\n",
       "         357: 2,\n",
       "         358: 3,\n",
       "         359: 14,\n",
       "         360: 10,\n",
       "         361: 2,\n",
       "         362: 33,\n",
       "         363: 14,\n",
       "         364: 7,\n",
       "         365: 2,\n",
       "         366: 2,\n",
       "         367: 22,\n",
       "         368: 21,\n",
       "         369: 234,\n",
       "         370: 8,\n",
       "         371: 89,\n",
       "         372: 3,\n",
       "         373: 3,\n",
       "         374: 446,\n",
       "         375: 55,\n",
       "         376: 3,\n",
       "         377: 2,\n",
       "         378: 2,\n",
       "         379: 5,\n",
       "         380: 6,\n",
       "         381: 7,\n",
       "         382: 2,\n",
       "         383: 2,\n",
       "         384: 54,\n",
       "         385: 15,\n",
       "         386: 8,\n",
       "         387: 252,\n",
       "         388: 36,\n",
       "         389: 7,\n",
       "         390: 2,\n",
       "         391: 3,\n",
       "         392: 30,\n",
       "         393: 4,\n",
       "         394: 3,\n",
       "         395: 7,\n",
       "         396: 59,\n",
       "         397: 16,\n",
       "         398: 2,\n",
       "         399: 2,\n",
       "         400: 5,\n",
       "         401: 61,\n",
       "         402: 51,\n",
       "         403: 6,\n",
       "         404: 10,\n",
       "         405: 2,\n",
       "         406: 7,\n",
       "         407: 146,\n",
       "         408: 3,\n",
       "         409: 40,\n",
       "         410: 5,\n",
       "         411: 4,\n",
       "         412: 4,\n",
       "         413: 209,\n",
       "         414: 2,\n",
       "         415: 30,\n",
       "         416: 2,\n",
       "         417: 2,\n",
       "         418: 2,\n",
       "         419: 9,\n",
       "         420: 4,\n",
       "         421: 3,\n",
       "         422: 4,\n",
       "         423: 12,\n",
       "         424: 5,\n",
       "         425: 3,\n",
       "         426: 2,\n",
       "         427: 2,\n",
       "         428: 2,\n",
       "         429: 126,\n",
       "         430: 4,\n",
       "         431: 4,\n",
       "         432: 3,\n",
       "         433: 57,\n",
       "         434: 18,\n",
       "         435: 5,\n",
       "         436: 3,\n",
       "         437: 3,\n",
       "         438: 5,\n",
       "         439: 7,\n",
       "         440: 17,\n",
       "         441: 15,\n",
       "         442: 5,\n",
       "         443: 8,\n",
       "         444: 3,\n",
       "         445: 127,\n",
       "         446: 30,\n",
       "         447: 5,\n",
       "         448: 26,\n",
       "         449: 8,\n",
       "         450: 4,\n",
       "         451: 13,\n",
       "         452: 2,\n",
       "         453: 16,\n",
       "         454: 3,\n",
       "         455: 117,\n",
       "         456: 15,\n",
       "         457: 3,\n",
       "         458: 31,\n",
       "         459: 2,\n",
       "         460: 147,\n",
       "         461: 5,\n",
       "         462: 52,\n",
       "         463: 3,\n",
       "         464: 3,\n",
       "         465: 2,\n",
       "         466: 7,\n",
       "         467: 25,\n",
       "         468: 7,\n",
       "         469: 2,\n",
       "         470: 10,\n",
       "         471: 11,\n",
       "         472: 8,\n",
       "         473: 2,\n",
       "         474: 2,\n",
       "         475: 202,\n",
       "         476: 412,\n",
       "         477: 35,\n",
       "         478: 10,\n",
       "         479: 13,\n",
       "         480: 78,\n",
       "         481: 19,\n",
       "         482: 2,\n",
       "         483: 28,\n",
       "         484: 3,\n",
       "         485: 3,\n",
       "         486: 2,\n",
       "         487: 2,\n",
       "         488: 6,\n",
       "         489: 4,\n",
       "         490: 2,\n",
       "         491: 9,\n",
       "         492: 3,\n",
       "         493: 4,\n",
       "         494: 34,\n",
       "         495: 6,\n",
       "         496: 7,\n",
       "         497: 3,\n",
       "         498: 3,\n",
       "         499: 2,\n",
       "         500: 2,\n",
       "         501: 4,\n",
       "         502: 2,\n",
       "         503: 70,\n",
       "         504: 11,\n",
       "         505: 111,\n",
       "         506: 25,\n",
       "         507: 70,\n",
       "         508: 2,\n",
       "         509: 2,\n",
       "         510: 2,\n",
       "         511: 7,\n",
       "         512: 6,\n",
       "         513: 3,\n",
       "         514: 2,\n",
       "         515: 2,\n",
       "         516: 3,\n",
       "         517: 5,\n",
       "         518: 7,\n",
       "         519: 10,\n",
       "         520: 96,\n",
       "         521: 8,\n",
       "         522: 3,\n",
       "         523: 8,\n",
       "         524: 2,\n",
       "         525: 15,\n",
       "         526: 6,\n",
       "         527: 55,\n",
       "         528: 4,\n",
       "         529: 5,\n",
       "         530: 26,\n",
       "         531: 6,\n",
       "         532: 20,\n",
       "         533: 8,\n",
       "         534: 5,\n",
       "         535: 15,\n",
       "         536: 26,\n",
       "         537: 3,\n",
       "         538: 12,\n",
       "         539: 2,\n",
       "         540: 14,\n",
       "         541: 14,\n",
       "         542: 3,\n",
       "         543: 9,\n",
       "         544: 170,\n",
       "         545: 2,\n",
       "         546: 452,\n",
       "         547: 9,\n",
       "         548: 7,\n",
       "         549: 302,\n",
       "         550: 23,\n",
       "         551: 14,\n",
       "         552: 2,\n",
       "         553: 81,\n",
       "         554: 67,\n",
       "         555: 8,\n",
       "         556: 2,\n",
       "         557: 3,\n",
       "         558: 48,\n",
       "         559: 3,\n",
       "         560: 2,\n",
       "         561: 2,\n",
       "         562: 19,\n",
       "         563: 12,\n",
       "         564: 3,\n",
       "         565: 3,\n",
       "         566: 3,\n",
       "         567: 4,\n",
       "         568: 3,\n",
       "         569: 18,\n",
       "         570: 8,\n",
       "         571: 7,\n",
       "         572: 2,\n",
       "         573: 8,\n",
       "         574: 86,\n",
       "         575: 4,\n",
       "         576: 9,\n",
       "         577: 139,\n",
       "         578: 15,\n",
       "         579: 4,\n",
       "         580: 5,\n",
       "         581: 24,\n",
       "         582: 14,\n",
       "         583: 48,\n",
       "         584: 10,\n",
       "         585: 16,\n",
       "         586: 19,\n",
       "         587: 10,\n",
       "         588: 3,\n",
       "         589: 9,\n",
       "         590: 2,\n",
       "         591: 7,\n",
       "         592: 7,\n",
       "         593: 18,\n",
       "         594: 4,\n",
       "         595: 27,\n",
       "         596: 2,\n",
       "         597: 34,\n",
       "         598: 4,\n",
       "         599: 3,\n",
       "         600: 6,\n",
       "         601: 4,\n",
       "         602: 7,\n",
       "         603: 2,\n",
       "         604: 10,\n",
       "         605: 8,\n",
       "         606: 45,\n",
       "         607: 19,\n",
       "         608: 5,\n",
       "         609: 10,\n",
       "         610: 2,\n",
       "         611: 4,\n",
       "         612: 16,\n",
       "         613: 9,\n",
       "         614: 36,\n",
       "         615: 12,\n",
       "         616: 17,\n",
       "         617: 30,\n",
       "         618: 5,\n",
       "         619: 13,\n",
       "         620: 8,\n",
       "         621: 2,\n",
       "         622: 2,\n",
       "         623: 2,\n",
       "         624: 66,\n",
       "         625: 4,\n",
       "         626: 3,\n",
       "         627: 3,\n",
       "         628: 18,\n",
       "         629: 4,\n",
       "         630: 30,\n",
       "         631: 23,\n",
       "         632: 129,\n",
       "         633: 2,\n",
       "         634: 8,\n",
       "         635: 2,\n",
       "         636: 2,\n",
       "         637: 28,\n",
       "         638: 16,\n",
       "         639: 4,\n",
       "         640: 4,\n",
       "         641: 7,\n",
       "         642: 22,\n",
       "         643: 2,\n",
       "         644: 2,\n",
       "         645: 2,\n",
       "         646: 2,\n",
       "         647: 8,\n",
       "         648: 9,\n",
       "         649: 6,\n",
       "         650: 64,\n",
       "         651: 3,\n",
       "         652: 54,\n",
       "         653: 30,\n",
       "         654: 6,\n",
       "         655: 5,\n",
       "         656: 2,\n",
       "         657: 4,\n",
       "         658: 2,\n",
       "         659: 48,\n",
       "         660: 22,\n",
       "         661: 34,\n",
       "         662: 2,\n",
       "         663: 2,\n",
       "         664: 2,\n",
       "         665: 30,\n",
       "         666: 2,\n",
       "         667: 5,\n",
       "         668: 2,\n",
       "         669: 3,\n",
       "         670: 9,\n",
       "         671: 2,\n",
       "         672: 3,\n",
       "         673: 2,\n",
       "         674: 43,\n",
       "         675: 3,\n",
       "         676: 5,\n",
       "         677: 83,\n",
       "         678: 3,\n",
       "         679: 3,\n",
       "         680: 14,\n",
       "         681: 13,\n",
       "         682: 5,\n",
       "         683: 4,\n",
       "         684: 79,\n",
       "         685: 2,\n",
       "         686: 191,\n",
       "         687: 30,\n",
       "         688: 3,\n",
       "         689: 2,\n",
       "         690: 67,\n",
       "         691: 2,\n",
       "         692: 2,\n",
       "         693: 3,\n",
       "         694: 5,\n",
       "         695: 7,\n",
       "         696: 46,\n",
       "         697: 2,\n",
       "         698: 86,\n",
       "         699: 67,\n",
       "         700: 7,\n",
       "         701: 61,\n",
       "         702: 9,\n",
       "         703: 3,\n",
       "         704: 9,\n",
       "         705: 18,\n",
       "         706: 8,\n",
       "         707: 7,\n",
       "         708: 2,\n",
       "         709: 23,\n",
       "         710: 4,\n",
       "         711: 3,\n",
       "         712: 4,\n",
       "         713: 2,\n",
       "         714: 2,\n",
       "         715: 21,\n",
       "         716: 2,\n",
       "         717: 12,\n",
       "         718: 10,\n",
       "         719: 7,\n",
       "         720: 2,\n",
       "         721: 27,\n",
       "         722: 81,\n",
       "         723: 14,\n",
       "         724: 2,\n",
       "         725: 3,\n",
       "         726: 6,\n",
       "         727: 6,\n",
       "         728: 77,\n",
       "         729: 2,\n",
       "         730: 32,\n",
       "         731: 4,\n",
       "         732: 3,\n",
       "         733: 18,\n",
       "         734: 2,\n",
       "         735: 7,\n",
       "         736: 14,\n",
       "         737: 2,\n",
       "         738: 46,\n",
       "         739: 2,\n",
       "         740: 4,\n",
       "         741: 2,\n",
       "         742: 4,\n",
       "         743: 28,\n",
       "         744: 4,\n",
       "         745: 4,\n",
       "         746: 6,\n",
       "         747: 3,\n",
       "         748: 2,\n",
       "         749: 4,\n",
       "         750: 3,\n",
       "         751: 6,\n",
       "         752: 8,\n",
       "         753: 2,\n",
       "         754: 72,\n",
       "         755: 3,\n",
       "         756: 5,\n",
       "         757: 46,\n",
       "         758: 2,\n",
       "         759: 21,\n",
       "         760: 7,\n",
       "         761: 17,\n",
       "         762: 95,\n",
       "         763: 3,\n",
       "         764: 2,\n",
       "         765: 3,\n",
       "         766: 13,\n",
       "         767: 5,\n",
       "         768: 4,\n",
       "         769: 54,\n",
       "         770: 4,\n",
       "         771: 2,\n",
       "         772: 6,\n",
       "         773: 2,\n",
       "         774: 5,\n",
       "         775: 2,\n",
       "         776: 7,\n",
       "         777: 3,\n",
       "         778: 9,\n",
       "         779: 5,\n",
       "         780: 2,\n",
       "         781: 4,\n",
       "         782: 5,\n",
       "         783: 6,\n",
       "         784: 53,\n",
       "         785: 2,\n",
       "         786: 3,\n",
       "         787: 30,\n",
       "         788: 3,\n",
       "         789: 8,\n",
       "         790: 2,\n",
       "         791: 3,\n",
       "         792: 47,\n",
       "         793: 28,\n",
       "         794: 5,\n",
       "         795: 2,\n",
       "         796: 13,\n",
       "         797: 2,\n",
       "         798: 10,\n",
       "         799: 2,\n",
       "         800: 2,\n",
       "         801: 14,\n",
       "         802: 3,\n",
       "         803: 2,\n",
       "         804: 4,\n",
       "         805: 2,\n",
       "         806: 20,\n",
       "         807: 3,\n",
       "         808: 4,\n",
       "         809: 8,\n",
       "         810: 2,\n",
       "         811: 2,\n",
       "         812: 8,\n",
       "         813: 3,\n",
       "         814: 34,\n",
       "         815: 3,\n",
       "         816: 13,\n",
       "         817: 5,\n",
       "         818: 2,\n",
       "         819: 2,\n",
       "         820: 4,\n",
       "         821: 2,\n",
       "         822: 4,\n",
       "         823: 69,\n",
       "         824: 22,\n",
       "         825: 2,\n",
       "         826: 2,\n",
       "         827: 3,\n",
       "         828: 5,\n",
       "         829: 136,\n",
       "         830: 2,\n",
       "         831: 3,\n",
       "         832: 14,\n",
       "         833: 4,\n",
       "         834: 11,\n",
       "         835: 3,\n",
       "         836: 9,\n",
       "         837: 2,\n",
       "         838: 2,\n",
       "         839: 6,\n",
       "         840: 4,\n",
       "         841: 51,\n",
       "         842: 69,\n",
       "         843: 5,\n",
       "         844: 4,\n",
       "         845: 68,\n",
       "         846: 21,\n",
       "         847: 2,\n",
       "         848: 3,\n",
       "         849: 12,\n",
       "         850: 2,\n",
       "         851: 10,\n",
       "         852: 2,\n",
       "         853: 44,\n",
       "         854: 2,\n",
       "         855: 5,\n",
       "         856: 5,\n",
       "         857: 5,\n",
       "         858: 3,\n",
       "         859: 2,\n",
       "         860: 4,\n",
       "         861: 138,\n",
       "         862: 2,\n",
       "         863: 7,\n",
       "         864: 4,\n",
       "         865: 28,\n",
       "         866: 3,\n",
       "         867: 2,\n",
       "         868: 2,\n",
       "         869: 2,\n",
       "         870: 10,\n",
       "         871: 2,\n",
       "         872: 4,\n",
       "         873: 3,\n",
       "         874: 5,\n",
       "         875: 2,\n",
       "         876: 9,\n",
       "         877: 7,\n",
       "         878: 52,\n",
       "         879: 28,\n",
       "         880: 9,\n",
       "         881: 2,\n",
       "         882: 37,\n",
       "         883: 4,\n",
       "         884: 7,\n",
       "         885: 210,\n",
       "         886: 2,\n",
       "         887: 5,\n",
       "         888: 4,\n",
       "         889: 62,\n",
       "         890: 7,\n",
       "         891: 14,\n",
       "         892: 72,\n",
       "         893: 39,\n",
       "         894: 4,\n",
       "         895: 2,\n",
       "         896: 7,\n",
       "         897: 2,\n",
       "         898: 6,\n",
       "         899: 13,\n",
       "         900: 47,\n",
       "         901: 8,\n",
       "         902: 29,\n",
       "         903: 7,\n",
       "         904: 6,\n",
       "         905: 12,\n",
       "         906: 4,\n",
       "         907: 6,\n",
       "         908: 167,\n",
       "         909: 13,\n",
       "         910: 4,\n",
       "         911: 10,\n",
       "         912: 41,\n",
       "         913: 2,\n",
       "         914: 14,\n",
       "         915: 51,\n",
       "         916: 3,\n",
       "         917: 4,\n",
       "         918: 3,\n",
       "         919: 3,\n",
       "         920: 9,\n",
       "         921: 2,\n",
       "         922: 348,\n",
       "         923: 2,\n",
       "         924: 2,\n",
       "         925: 3,\n",
       "         926: 4,\n",
       "         927: 2,\n",
       "         928: 7,\n",
       "         929: 23,\n",
       "         930: 3,\n",
       "         931: 13,\n",
       "         932: 3,\n",
       "         933: 5,\n",
       "         934: 4,\n",
       "         935: 2,\n",
       "         936: 7,\n",
       "         937: 4,\n",
       "         938: 2,\n",
       "         939: 3,\n",
       "         940: 21,\n",
       "         941: 9,\n",
       "         942: 19,\n",
       "         943: 3,\n",
       "         944: 9,\n",
       "         945: 4,\n",
       "         946: 3,\n",
       "         947: 3,\n",
       "         948: 10,\n",
       "         949: 2,\n",
       "         950: 10,\n",
       "         951: 22,\n",
       "         952: 30,\n",
       "         953: 12,\n",
       "         954: 20,\n",
       "         955: 2,\n",
       "         956: 2,\n",
       "         957: 6,\n",
       "         958: 17,\n",
       "         959: 9,\n",
       "         960: 2,\n",
       "         961: 101,\n",
       "         962: 15,\n",
       "         963: 18,\n",
       "         964: 169,\n",
       "         965: 2,\n",
       "         966: 4,\n",
       "         967: 36,\n",
       "         968: 9,\n",
       "         969: 7,\n",
       "         970: 23,\n",
       "         971: 3,\n",
       "         972: 5,\n",
       "         973: 2,\n",
       "         974: 14,\n",
       "         975: 192,\n",
       "         976: 2,\n",
       "         977: 2,\n",
       "         978: 55,\n",
       "         979: 20,\n",
       "         980: 11,\n",
       "         981: 16,\n",
       "         982: 74,\n",
       "         983: 45,\n",
       "         984: 3,\n",
       "         985: 64,\n",
       "         986: 12,\n",
       "         987: 2,\n",
       "         988: 69,\n",
       "         989: 4,\n",
       "         990: 5,\n",
       "         991: 6,\n",
       "         992: 5,\n",
       "         993: 7,\n",
       "         994: 8,\n",
       "         995: 7,\n",
       "         996: 2,\n",
       "         997: 16,\n",
       "         998: 19,\n",
       "         ...})"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce4cba-e0af-4bd1-b572-23d78448d1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
