{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import re\n",
    "#Importing everything from NLP Week 1 - following that as a guide for now\n",
    "import gzip\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.width = 150\n",
    "RANDOM_SEED = 696\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WikiLarge_Train_df = pd.read_csv(r'/Users/staceybruestle/Documents/Documents/Education/MADS/Coursework/aSIADS696- Milestone 2/Readability Project/Data/WikiLarge_Train.csv')#, \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WikiLarge_Train_df['parsed_list'] = 0\n",
    "WikiLarge_Train_df['All_Characters'] = 0\n",
    "WikiLarge_Train_df['Is_Int'] = 0\n",
    "for i, row in WikiLarge_Train_df.iterrows():\n",
    "        temp = row['original_text']\n",
    "        WikiLarge_Train_df['parsed_list'].at[i] = re.split(r'(\\s)', temp)\n",
    "        if temp.isalpha():\n",
    "                WikiLarge_Train_df['All_Characters'].at[i] = 1\n",
    "        try:\n",
    "                int(temp)\n",
    "                WikiLarge_Train_df['Is_Int'].at[i] = 1\n",
    "        except:\n",
    "                pass\n",
    "#parsed_list = is the sentence split on whitespace, retaining each whitespace as an element in the list\n",
    "print(WikiLarge_Train_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df, test_df = np.split(WikiLarge_Train_df.sample(frac=1, random_state= RANDOM_SEED), \n",
    "                       [int(.8*len(WikiLarge_Train_df)), int(.9*len(WikiLarge_Train_df))], axis = 0)\n",
    "#Make list of labels\n",
    "y_train = list(train_df.label)\n",
    "y_dev = list(dev_df.label)\n",
    "y_test = list(test_df.label)\n",
    "# print(train_df.shape)\n",
    "# print(dev_df.shape)\n",
    "# print(test_df.shape)\n",
    "# 333414, 41677, 41677 all with 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 333414/333414 [00:08<00:00, 39238.84it/s]\n"
     ]
    }
   ],
   "source": [
    "ws_tokens = Counter()  #split on whitespace\n",
    "alpha_ws_tokens = Counter() #split on white space, keeps each word once like a set, only keeping tokens containing alphanumeric chars\n",
    "alpha_re_tokens = Counter() # split on white space keeping every portion of each token without other chars\n",
    "                            # example: \"don't\" is included in ws_tokens, not in alpha_ws_tokens, and \"don\", \"t\" is in alpha_re_tokens\n",
    "count = 0\n",
    "\n",
    "for sent in tqdm(train_df.original_text):\n",
    "    alphanumeric_list = []\n",
    "    alpha_re_list = []\n",
    "    sentlist = sent.split()\n",
    "\n",
    "    ws_tokens.update(sentlist)\n",
    "\n",
    "    for element in sentlist:\n",
    "        #alphanumeric_regex = re.compile(r'[a-zA-Z0-9]+')\n",
    "        alphanumeric_regex = re.compile(r'\\w+')\n",
    "        if re.fullmatch(alphanumeric_regex, element) != None:\n",
    "            alphanumeric_list.append(element)\n",
    "            #print(\"element:\", element, \"\\nalpha_ws_list:\",alpha_ws_list)\n",
    "\n",
    "    alpha_re_list = re.findall(alphanumeric_regex, sent)\n",
    "    alpha_ws_tokens.update(alphanumeric_list)\n",
    "    alpha_re_tokens.update(alpha_re_list)\n",
    "    # ws_tokens results in 180497 tokens\n",
    "    # alpha_ws_tokens results in 150320 tokens\n",
    "    # alpha_re_tokens results in 155812"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_50 = alpha_re_tokens.most_common(50)\n",
    "# #hidden tests are within this cell\n",
    "# top_50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert text to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333414, 1099)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=500, stop_words= 'english')\n",
    "X_train = vectorizer.fit_transform(train_df.original_text)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500, multi_class=&#x27;ovr&#x27;, random_state=696,\n",
       "                   solver=&#x27;newton-cholesky&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500, multi_class=&#x27;ovr&#x27;, random_state=696,\n",
       "                   solver=&#x27;newton-cholesky&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=500, multi_class='ovr', random_state=696,\n",
       "                   solver='newton-cholesky')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=RANDOM_SEED, max_iter=500, multi_class='ovr', solver= 'newton-cholesky')\n",
    "#clf.fit(X_train[0:10000,:], y_train[0:10000])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Generate the dev data\n",
    "X_dev = vectorizer.transform(dev_df.original_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Dummy Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(random_state=696, strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(random_state=696, strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(random_state=696, strategy='most_frequent')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_dummy = DummyClassifier(strategy='uniform', random_state = RANDOM_SEED, constant=None)\n",
    "most_freq_dummy = DummyClassifier(strategy='most_frequent', random_state = RANDOM_SEED, constant=None)\n",
    "\n",
    "uniform_dummy.fit(X_train, y_train)\n",
    "most_freq_dummy.fit(X_train, y_train)\n",
    "\n",
    "# Generate the predictions\n",
    "lr_tiny_dev_preds = clf.predict(X_dev)\n",
    "rand_dev_preds = uniform_dummy.predict(X_dev)\n",
    "mf_dev_preds = most_freq_dummy.predict(X_dev)\n",
    "\n",
    "# Score the predictions\n",
    "lr_f1 = f1_score(y_dev, lr_tiny_dev_preds, average='macro')\n",
    "rand_f1 = f1_score(y_dev, rand_dev_preds, average='macro')\n",
    "mf_f1 = f1_score(y_dev, mf_dev_preds, average='macro')\n",
    "print(lr_f1)\n",
    "print(rand_f1)\n",
    "print(mf_f1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function for the steps so we can run it for various amounts of data to see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:32<00:00, 18.46s/it]\n"
     ]
    }
   ],
   "source": [
    "def train_and_score(train_df, dev_df):\n",
    "    # Fit a new TfidfVectorizer\n",
    "    #vectorizer = TfidfVectorizer(min_df=25, stop_words= 'english')\n",
    "    vectorizer = TfidfVectorizer(min_df=25, max_df= .9)\n",
    "    X_train = vectorizer.fit_transform(train_df.original_text)\n",
    "\n",
    "    #Get the labels\n",
    "    y_train = list(train_df.label)\n",
    "\n",
    "    #Fit the data to a Logistic Regression Classifier (in this example a subset of 10k)\n",
    "    #clf = LogisticRegression(random_state=RANDOM_SEED, multi_class='auto', solver= 'lbfgs')\n",
    "    clf = LogisticRegression(random_state=RANDOM_SEED, max_iter=500, C=.1, multi_class='ovr', solver= 'newton-cholesky')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Generate the dev data\n",
    "    X_dev = vectorizer.transform(dev_df.original_text)\n",
    "    y_dev = list(dev_df.label)\n",
    "\n",
    "    # Generate the predictions\n",
    "    lr_tiny_dev_preds = clf.predict(X_dev)\n",
    "\n",
    "    # Score the predictions\n",
    "    f1 = f1_score(y_dev, lr_tiny_dev_preds, average='macro')\n",
    "\n",
    "    # the function returns the macro-averaged F1 score on the dev data\n",
    "    return f1\n",
    "\n",
    "def change_in_performance(training_sizes, train_df, dev_df):\n",
    "    random.seed(RANDOM_SEED)\n",
    "    f1_scores = []\n",
    "    for training_size in tqdm(training_sizes):\n",
    "        f1_scores.append(train_and_score(train_df.head(training_size), dev_df))\n",
    "    return(f1_scores)\n",
    "\n",
    "training_sizes = [1000, 10000, 50000, 100000, 333414]\n",
    "performace_f1_scores = change_in_performance(training_sizes, train_df, dev_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a uni, bi, and trigram vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333414, 23797)\n"
     ]
    }
   ],
   "source": [
    "trigram_vectorizer = TfidfVectorizer(stop_words='english', min_df=25, ngram_range=(1,3))\n",
    "X_train = trigram_vectorizer.fit_transform(train_df.original_text)\n",
    "print(X_train.shape)\n",
    "clf = LogisticRegression(random_state=RANDOM_SEED, multi_class='ovr', solver= 'newton-cholesky')\n",
    "clf.fit(X_train, y_train)\n",
    "#featurize the dev data\n",
    "X_dev = trigram_vectorizer.transform(dev_df.original_text)\n",
    "#predict the dev data and score\n",
    "lr_trigram_dev_preds = clf.predict(X_dev)\n",
    "lr_f1 = f1_score(y_dev, lr_trigram_dev_preds, average='macro')\n",
    "print(lr_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_df @ 500, ngram_range(1,3), multi_class='ovr', solver = 'newton-cholesky' (didn't take too long) scored 0.6451618658\n",
    "min_df @  25, ngram_range(1,3), multi_class='ovr', solver = 'newton-cholesky' (6m 19.1s) scored 0.6880169450552442"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (v3.10.4:9d38120e33, Mar 23 2022, 17:29:05) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
