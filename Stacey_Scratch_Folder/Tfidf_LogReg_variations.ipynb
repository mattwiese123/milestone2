{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import re\n",
    "#Importing everything from NLP Week 1 - following that as a guide for now\n",
    "import gzip\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.width = 150\n",
    "RANDOM_SEED = 696\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WikiLarge_Train_df = pd.read_csv(r'/Users/staceybruestle/Documents/Documents/Education/MADS/Coursework/aSIADS696- Milestone 2/Readability Project/Data/WikiLarge_Train.csv')#, \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df, test_df = np.split(WikiLarge_Train_df.sample(frac=1, random_state= RANDOM_SEED), \n",
    "                       [int(.8*len(WikiLarge_Train_df)), int(.9*len(WikiLarge_Train_df))], axis = 0)\n",
    "#Make list of labels\n",
    "y_train = list(train_df.label)\n",
    "y_dev = list(dev_df.label)\n",
    "y_test = list(test_df.label)\n",
    "# Shapes: 333414, 41677, 41677 all with 5 columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Dummy Classifiers to use as reference for other scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummyClassifierScores(train_df, dev_df, vectorizer, min_df=1, stop_words= None, strategy='uniform'):\n",
    "    # Stratgeies 'uniform' and 'most_frequent'\n",
    "    X_train = vectorizer.fit_transform(train_df.original_text)\n",
    "    X_dev = vectorizer.transform(dev_df.original_text)\n",
    "\n",
    "    dummy = DummyClassifier(strategy= strategy, random_state = RANDOM_SEED, constant=None)\n",
    "    dummy.fit(X_train, y_train)\n",
    "\n",
    "    # Generate the predictions\n",
    "    dev_preds = dummy.predict(X_dev)\n",
    "\n",
    "    # Score the predictions\n",
    "    f1_dummy = f1_score(y_dev, dev_preds, average='macro')\n",
    "\n",
    "    return f1_dummy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function for the steps so we can run it for various amounts of data to see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function returns the macro-averaged F1 score on the dev data and the dummy if requested\n",
    "def train_and_score(train_df, dev_df, min_df=1, max_df = 1.0, max_iter=100, C=1.0, \\\n",
    "                    ngram_range=(1,1), stop_words= None, dummy='no', strategy='uniform'):\n",
    "    # Fit a new TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(min_df= min_df, max_df= max_df, stop_words= stop_words, ngram_range= ngram_range)\n",
    "    X_train = vectorizer.fit_transform(train_df.original_text)\n",
    "\n",
    "    #Get the labels\n",
    "    y_train = list(train_df.label)\n",
    "\n",
    "    #Fit the data to a Logistic Regression Classifier\n",
    "    #'newton-cholesky' not working now - I must have been using a more recent version of python previously\n",
    "    clf = LogisticRegression(random_state=RANDOM_SEED, max_iter = max_iter, C= C, multi_class='ovr', solver= 'newton-cg')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Generate the dev data\n",
    "    X_dev = vectorizer.transform(dev_df.original_text)\n",
    "    y_dev = list(dev_df.label)\n",
    "\n",
    "    # Generate the predictions\n",
    "    lr_tiny_dev_preds = clf.predict(X_dev)\n",
    "\n",
    "    # Score the predictions\n",
    "    f1 = f1_score(y_dev, lr_tiny_dev_preds, average='macro')\n",
    "\n",
    "    if dummy== 'yes':\n",
    "        f1 = (f1, dummyClassifierScores(train_df, dev_df, vectorizer, min_df, stop_words, strategy= strategy))\n",
    "\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All defaults with uniform dummy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6834110283504679, 0.49840355363816646)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"All defaults with uniform dummy:\")\n",
    "train_and_score(train_df, dev_df, dummy='yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All defaults - most frequent dummy: 0.333061289806369\n"
     ]
    }
   ],
   "source": [
    "# Need to create the vectorizer to run dummyClassifierScores by itself\n",
    "vectorizer = TfidfVectorizer()\n",
    "print(\"All defaults - most frequent dummy:\", \\\n",
    "dummyClassifierScores(train_df, dev_df, vectorizer, strategy= 'most_frequent') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default with stopwords: 0.6605484429405641\n"
     ]
    }
   ],
   "source": [
    "print(\"default with stopwords:\", \\\n",
    "train_and_score(train_df, dev_df, stop_words= 'english') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6921716051041282"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6925312886757502"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931104461778711"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6925343220490136"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6926548631383732"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.692797250901643"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6925819160350151"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=26)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like leaving all others as defaults and playing with min_df, min_df = 25 is the best. 0.6931104461778711"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931104461778711"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931104461778711"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why didn't things change using a different max_df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6880147795379578"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931104461778711"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6932060383885735"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intersesting. .1 went down but not as much as I would have expected. .6 went up slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6932060383885735"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = 0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.5 was the same as 0.6.  0.4 went down. So it looks like 0.6 or 0.5 might be good for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6914490573484454"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try working with another max_iter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931104461778711"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .9, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931104461778711"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .9, max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931104461778711"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .9, max_iter=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931104461778711"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .9, max_iter=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why aren't we seeing a change at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931104461778711"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .9, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6932544131304068"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .9, C= .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6929172936912404"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .9, C= .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6925834197233214"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .9, C= .7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best so far for C was .9. Lets try slightly higher and slightly lower   0.6932544131304068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6930620712550157"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .9, C= .85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6930620712550157"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .9, C= .95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6932544131304068"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .9, C= .9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = .9 looks best.  0.6932544131304068\n",
    "Now play with n_grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7101257948813133"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .9, C= .9, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7104838972466732"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_score(train_df, dev_df, min_df=25, max_df = .9, C= .9, ngram_range=(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_score(train_df, dev_df, min_df=1, max_df = 1.0, max_iter=100, C=1.0, \\\n",
    "#                     ngram_range=(1,1), stop_words= None, dummy='no', strategy='uniform')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e6f7cd0ebba2aa2c388bbed66ebc49096d476d4216b999bf7270ff51b8a6e94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
