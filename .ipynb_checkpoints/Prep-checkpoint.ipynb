{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import re\n",
    "#Importing everything from NLP Week 1 - following that as a guide for now\n",
    "import gzip\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.width = 150\n",
    "RANDOM_SEED = 696\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_option(\"display.width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WikiLarge_Train_df = pd.read_csv(r'assets/WikiLarge_Train.csv')#, \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(WikiLarge_Train_df.tail())\n",
    "# print(WikiLarge_Train_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WikiLarge_Train_df['parsed_list'] = 0\n",
    "WikiLarge_Train_df['All_Characters'] = 0\n",
    "WikiLarge_Train_df['Is_Int'] = 0\n",
    "for i, row in WikiLarge_Train_df.iterrows():\n",
    "        temp = row['original_text']\n",
    "        WikiLarge_Train_df['parsed_list'].at[i] = re.split(r'(\\s)', temp)\n",
    "        if temp.isalpha():\n",
    "                WikiLarge_Train_df['All_Characters'].at[i] = 1\n",
    "        try:\n",
    "                int(temp)\n",
    "                WikiLarge_Train_df['Is_Int'].at[i] = 1\n",
    "        except:\n",
    "                pass\n",
    "\n",
    "        #WikiLarge_Train_df['parsed_list'].at[i] = re.split(r'(-|,|\\s)\\s*', temp)\n",
    "        # Do we need to be greedy?\n",
    "\n",
    "# Are commas always split by spaces?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       original_text  label                                        parsed_list  All_Characters  Is_Int\n",
      "0  There is manuscript evidence that Austen conti...      1  [There,  , is,  , manuscript,  , evidence,  , ...               0       0\n",
      "1  In a remarkable comparative analysis , Mandaea...      1  [In,  , a,  , remarkable,  , comparative,  , a...               0       0\n",
      "2  Before Persephone was released to Hermes , who...      1  [Before,  , Persephone,  , was,  , released,  ...               0       0\n",
      "3  Cogeneration plants are commonly found in dist...      1  [Cogeneration,  , plants,  , are,  , commonly,...               0       0\n",
      "4  Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1  [Geneva,  , -LRB-,  , ,,  , ;,  , ,,  , ;,  , ...               0       0\n"
     ]
    }
   ],
   "source": [
    "print(WikiLarge_Train_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    407992\n",
       "1      8776\n",
       "Name: All_Characters, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WikiLarge_Train_df['All_Characters'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    416718\n",
      "1        50\n",
      "Name: Is_Int, dtype: int64\n",
      "0    40\n",
      "1    10\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Not many -so I'm not going to worry about these\n",
    "print(WikiLarge_Train_df['Is_Int'].value_counts())\n",
    "print(WikiLarge_Train_df[WikiLarge_Train_df['Is_Int'] ==1 ]['label'].value_counts())\n",
    "# The following shows there's no rhyme or reason to the way they're flagged\n",
    "# WikiLarge_Train_df[WikiLarge_Train_df['Is_Int'] ==1 ].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, lets divide the set into train dev and test just for fun and see about getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df, test_df = np.split(WikiLarge_Train_df.sample(frac=1, random_state= RANDOM_SEED), \n",
    "                       [int(.8*len(WikiLarge_Train_df)), int(.9*len(WikiLarge_Train_df))], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333414, 5)\n",
      "(41677, 5)\n",
      "(41677, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(dev_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FROM NLP Week 1:\n",
    "\n",
    "What tokens should count as a \"word\" and how do we find them? For this exercise, we'll try extract three kinds of tokens using different methods to see what happens\n",
    "\n",
    "1. ws_tokens: dict count of tokens separated by whitespace\n",
    "2. alpha_ws_tokens: dict count of tokens separated by whitespace and are alpha numeric\n",
    "3. alpha_re_tokens: dict count of tokens separated by word boundaries that only consist of alphanumeric characters\n",
    "\n",
    "As quick example of how these are different, let's say we have the sentence \"My computer says 'I don't know...' but after thinking about it, I think it does.\"\n",
    "\n",
    "* The first case should return ['My', 'computer', 'says', \"'I\", \"don't\", \"know...'\", 'but', 'after', 'thinking', 'about', 'it,', 'I', 'think', 'it', 'does.'], which we can see contains a bunch of tokens that have punctuation with them.\n",
    "\n",
    "* The second case should return ['My', 'computer', 'says', 'but', 'after', 'thinking', 'about', 'I', 'think', 'it'] which is filtering out a lot more tokens. We see that any token with any punctuation gets removed. This is probably too much but the tokens do look cleaner\n",
    "\n",
    "* The third case should return ['My', 'computer', 'says', 'I', 'don', 't', 'know', 'but', 'after', 'thinking', 'about', 'it', 'I', 'think', 'it', 'does'], which gives us all the tokens. Here we see that it's also split \"don't\" into two tokens too! We could modify our regex some to allow intra-token punctuation to avoid this but for now we'll keep it a it simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 333414/333414 [00:12<00:00, 25952.91it/s]\n"
     ]
    }
   ],
   "source": [
    "ws_tokens = Counter()\n",
    "alpha_ws_tokens = Counter()\n",
    "alpha_re_tokens = Counter()\n",
    "count = 0\n",
    "\n",
    "for sent in tqdm(train_df.original_text):\n",
    "#if count > 1:\n",
    "    alphanumeric_list = []\n",
    "    alpha_re_list = []\n",
    "    sentlist = sent.split()\n",
    "\n",
    "    ws_tokens.update(sentlist)\n",
    "\n",
    "    for element in sentlist:\n",
    "        #alphanumeric_regex = re.compile(r'[a-zA-Z0-9]+')\n",
    "        alphanumeric_regex = re.compile(r'\\w+')\n",
    "        if re.fullmatch(alphanumeric_regex, element) != None:\n",
    "            alphanumeric_list.append(element)\n",
    "            #print(\"element:\", element, \"\\nalpha_ws_list:\",alpha_ws_list)\n",
    "\n",
    "    alpha_re_list = re.findall(alphanumeric_regex, sent)\n",
    "    alpha_ws_tokens.update(alphanumeric_list)\n",
    "    alpha_re_tokens.update(alpha_re_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180497\n",
      "150320\n",
      "155812\n"
     ]
    }
   ],
   "source": [
    "print(len(ws_tokens))\n",
    "print(len(alpha_ws_tokens))\n",
    "print(len(alpha_re_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 388051),\n",
       " ('of', 231298),\n",
       " ('in', 184434),\n",
       " ('and', 168008),\n",
       " ('a', 146692),\n",
       " ('is', 130853),\n",
       " ('to', 99037),\n",
       " ('RRB', 87115),\n",
       " ('LRB', 86878),\n",
       " ('The', 69017),\n",
       " ('was', 65924),\n",
       " ('as', 47474),\n",
       " ('for', 42317),\n",
       " ('by', 42126),\n",
       " ('on', 40038),\n",
       " ('with', 33040),\n",
       " ('s', 30582),\n",
       " ('that', 29589),\n",
       " ('from', 29501),\n",
       " ('are', 27668),\n",
       " ('an', 27376),\n",
       " ('or', 26066),\n",
       " ('It', 23917),\n",
       " ('at', 22762),\n",
       " ('his', 19793),\n",
       " ('which', 18768),\n",
       " ('In', 18721),\n",
       " ('it', 17895),\n",
       " ('also', 16284),\n",
       " ('has', 15611),\n",
       " ('be', 15144),\n",
       " ('he', 14975),\n",
       " ('born', 14891),\n",
       " ('first', 14506),\n",
       " ('were', 13468),\n",
       " ('France', 13454),\n",
       " ('He', 13349),\n",
       " ('one', 12754),\n",
       " ('known', 11524),\n",
       " ('who', 11262),\n",
       " ('United', 11159),\n",
       " ('not', 10888),\n",
       " ('its', 10738),\n",
       " ('department', 10574),\n",
       " ('have', 10282),\n",
       " ('city', 10253),\n",
       " ('A', 10196),\n",
       " ('de', 10067),\n",
       " ('1', 9896),\n",
       " ('commune', 9647)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_50 = alpha_re_tokens.most_common(50)\n",
    "#hidden tests are within this cell\n",
    "top_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155812 0 155811\n",
      "155812 0.05914372062349407 1.5241223608106686e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the word distribution\n",
    "dict_pairs = dict(alpha_re_tokens)\n",
    "total_counts = sum(dict_pairs.values())\n",
    "\n",
    "#sorted_dict = {}\n",
    "sorted_keys = sorted(dict_pairs, key=dict_pairs.get, reverse=True) \n",
    "x = [] #rank\n",
    "y = [] #probability\n",
    "count = 0\n",
    "for w in sorted_keys:\n",
    "    #print(w, dict_pairs[w], sorted_dict)\n",
    "    x.append(count)\n",
    "    y.append(dict_pairs[w] / total_counts)\n",
    "    count += 1\n",
    "\n",
    "print(len(x), x[0], x[-1])\n",
    "print(len(y), y[0], y[-1])\n",
    "\n",
    "ax = plt.plot(x, y, '.')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert text to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333414, 1099)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=500, stop_words= 'english')\n",
    "X_train = vectorizer.fit_transform(train_df.original_text)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make list of labels\n",
    "y_train = list(train_df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the classifier - using all the data but could narrow this down to save time. Lets just see if it takes a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500, multi_class=&#x27;ovr&#x27;, random_state=696,\n",
       "                   solver=&#x27;newton-cholesky&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500, multi_class=&#x27;ovr&#x27;, random_state=696,\n",
       "                   solver=&#x27;newton-cholesky&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=500, multi_class='ovr', random_state=696,\n",
       "                   solver='newton-cholesky')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=RANDOM_SEED, max_iter=500, multi_class='ovr', solver= 'newton-cholesky')\n",
    "#clf.fit(X_train[0:10000,:], y_train[0:10000])\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev = vectorizer.transform(dev_df.original_text)\n",
    "y_dev = list(dev_df.label)\n",
    "type(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Dummy Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(random_state=696, strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(random_state=696, strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(random_state=696, strategy='most_frequent')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_dummy = DummyClassifier(strategy='uniform', random_state = RANDOM_SEED, constant=None)\n",
    "most_freq_dummy = DummyClassifier(strategy='most_frequent', random_state = RANDOM_SEED, constant=None)\n",
    "\n",
    "uniform_dummy.fit(X_train, y_train)\n",
    "most_freq_dummy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tiny_dev_preds = clf.predict(X_dev)\n",
    "rand_dev_preds = uniform_dummy.predict(X_dev)\n",
    "mf_dev_preds = most_freq_dummy.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6421682653633889\n",
      "0.49840355363816646\n",
      "0.333061289806369\n"
     ]
    }
   ],
   "source": [
    "lr_f1 = f1_score(y_dev, lr_tiny_dev_preds, average='macro')\n",
    "rand_f1 = f1_score(y_dev, rand_dev_preds, average='macro')\n",
    "mf_f1 = f1_score(y_dev, mf_dev_preds, average='macro')\n",
    "print(lr_f1)\n",
    "print(rand_f1)\n",
    "print(mf_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function for the steps so we can run it for various amounts of data to see the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matt experiments:\n",
    "\n",
    "### 1\n",
    " TfidfVectorizer(min_df=25, max_df= .9, strip_accents='ascii' ,stop_words='english', analyzer='char_wb', ngram_range=(1,3))\n",
    " \n",
    " LogisticRegression(random_state=RANDOM_SEED, max_iter=500, C=.1, multi_class='ovr', solver= 'newton-cg')\n",
    " \n",
    " [0.5367548454017107, 0.655777640516025, 0.674599129866489, 0.6804460573909678, 0.688381517756455]\n",
    "\n",
    "### 2\n",
    " TfidfVectorizer(min_df=25, max_df= .9, strip_accents='ascii' ,stop_words='english', analyzer='char_wb', ngram_range=(1,3), lowercase=False)\n",
    " \n",
    "  LogisticRegression(random_state=RANDOM_SEED, max_iter=500, C=.1, multi_class='ovr', solver= 'newton-cg')\n",
    " \n",
    " [0.5431826182998672, 0.6592851964393285, 0.6770780203143197, 0.682915289861274, 0.6933228754367546]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/matt/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Vectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=25, max_df= .9, strip_accents='ascii',  analyzer='char_wb', ngram_range=(1,3), lowercase=False)\n",
    "\n",
    "# Transform data and labels\n",
    "X_train = vectorizer.fit_transform(train_df.original_text)\n",
    "y_train = list(train_df.label)\n",
    "\n",
    "# Pipeline and grid\n",
    "pipeline = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier': [LogisticRegression()],WW\n",
    "     'classifier__penalty' : ['l2'],\n",
    "     'classifier__C': np.logspace(0,4,50),\n",
    "     'classifier__solver': ['newton-cholesky', 'newton-cg'],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Grid setup and train\n",
    "clf = GridSearchCV(pipeline, param_grid=param_grid, cv=3, n_jobs=4, pre_dispatch=4)\n",
    "\n",
    "best_clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(solver='newton-cholesky'),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'newton-cholesky'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5/5 [05:32<00:00, 66.54s/it]\n"
     ]
    }
   ],
   "source": [
    "def train_and_score(train_df, dev_df):\n",
    "    # Fit a new TfidfVectorizer\n",
    "    #vectorizer = TfidfVectorizer(min_df=25, stop_words= 'english')\n",
    "    vectorizer = TfidfVectorizer(min_df=25, max_df= .9, strip_accents='ascii',  analyzer='char_wb', ngram_range=(1,3), lowercase=False)\n",
    "    X_train = vectorizer.fit_transform(train_df.original_text)\n",
    "\n",
    "    #Get the labels\n",
    "    y_train = list(train_df.label)\n",
    "\n",
    "    #Fit the data to a Logistic Regression Classifier (in this example a subset of 10k)\n",
    "    #clf = LogisticRegression(random_state=RANDOM_SEED, multi_class='auto', solver= 'lbfgs')\n",
    "    clf = LogisticRegression(random_state=RANDOM_SEED, max_iter=500, C=1, multi_class='ovr', solver= 'newton-cholesky')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Generate the dev data\n",
    "    X_dev = vectorizer.transform(dev_df.original_text)\n",
    "    y_dev = list(dev_df.label)\n",
    "\n",
    "    # Generate the predictions\n",
    "    lr_tiny_dev_preds = clf.predict(X_dev)\n",
    "\n",
    "    # Score the predictions\n",
    "    f1 = f1_score(y_dev, lr_tiny_dev_preds, average='macro')\n",
    "\n",
    "    # the function returns the macro-averaged F1 score on the dev data\n",
    "    return f1\n",
    "\n",
    "def change_in_performance(training_sizes, train_df, dev_df):\n",
    "    random.seed(RANDOM_SEED)\n",
    "    f1_scores = []\n",
    "    for training_size in tqdm(training_sizes):\n",
    "        f1_scores.append(train_and_score(train_df.head(training_size), dev_df))\n",
    "    return(f1_scores)\n",
    "\n",
    "training_sizes = [1000, 10000, 50000, 100000, 333414]\n",
    "performace_f1_scores = change_in_performance(training_sizes, train_df, dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used these tips from NLP Week 1 to fine tune:\n",
    "\n",
    "Overall lots of room for improvement. We could certainly try fine-tuning some of the hyperparameters though! Some useful ideas to try by altering the TF-IDF vectorizer or classifier:\n",
    "* use lower `min_df` to increase the number of features\n",
    "* don't use stopword removal\n",
    "* tune the `C` parameter on the logistic regression classifier\n",
    "* don't lower-case the text \n",
    "* use a `CountVectorizer` instead of a TF-IDF vectorizer\n",
    "* set `max_df` to remove common features\n",
    "\n",
    "Which do you think will lead to higher performance? Try some out and report on the Slack or Piazza what's the highest performance you can achieve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6183723953111302, 0.6673916826003882, 0.6818282649034958, 0.6877756360255619, 0.6962710421128029]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='num_instances', ylabel='f1'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGxCAYAAACeKZf2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsqElEQVR4nO3df1hVZb738c9WZEOo+Cv5kYiUphZqtukoesyZfmBWZtYko2V51I4MmZlTzmE854ScCk+PEf3CdFLJZipPY3bVROl2Jk0Ha5KgKLNjpUG2iaQCdQoU7ucPH/czOxApgbW5fb+ua13XrHvd617ftVaOH++1194uY4wRAACAJTo5XQAAAEBrItwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKwS4nQB7a2hoUFffPGFunXrJpfL5XQ5AACgBYwxOnjwoGJjY9WpU/NzM6dduPniiy8UFxfndBkAAOAnKC8vV79+/Zrtc9qFm27dukk6dnG6d+/ucDUAAKAlampqFBcX5/97vDmnXbg5/iiqe/fuhBsAADqYlnykhA8UAwAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWcTzc5OXlKSEhQWFhYfJ4PNq2bdsJ+86cOVMul6vRcv7557djxQAAIJg5Gm7WrVunBQsWaPHixSouLta4ceM0ceJElZWVNdn/4Ycfls/n8y/l5eXq1auXbrjhhnauHAAABCuXMcY4dfBRo0bpwgsv1PLly/1tQ4cO1bXXXqvs7OyT7v/iiy/quuuu0969exUfH9+iY9bU1CgyMlLV1dX8/AIAAB3Ej/n727GZm7q6OhUVFSklJSWgPSUlRYWFhS0aY9WqVbrssstaHGwAAID9HPvhzAMHDqi+vl5RUVEB7VFRUaqoqDjp/j6fT6+++qqeeeaZZvvV1taqtrbWv15TU/PTCgYAAB2C4x8o/uGvexpjWvSLn/n5+erRo4euvfbaZvtlZ2crMjLSv8TFxZ1KuQAAIMg5Fm769Omjzp07N5qlqaysbDSb80PGGK1evVozZsxQaGhos30zMjJUXV3tX8rLy0+5dgAAELwceywVGhoqj8cjr9erKVOm+Nu9Xq8mT57c7L5bt27Vxx9/rNmzZ5/0OG63W263+5TrBQCgOY/9+mWnS+iw5j04qVXHcyzcSNLChQs1Y8YMJSUlKTk5WStXrlRZWZnS0tIkHZt12b9/v9auXRuw36pVqzRq1CglJiY6UTYAAAhijoab1NRUVVVVKSsrSz6fT4mJiSooKPC//eTz+Rp95011dbXWr1+vhx9+2ImSAQBAkHP0e26cwPfcAADaAo+lfrqWPJb6MX9/OzpzAwA4NVsvHu90CR3W+De2Ol0C2ojjr4IDAAC0JsINAACwCo+lAPxoYx8d63QJHdZfb/+r0yUA1mPmBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKrwKjg6jLGuY0yV0WP3/s9TpEgCg3TBzAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWCXE6QKCmefutU6X0KEV/Z+bnS4BAHAaYuYGAABYhXADAACsQrgBAABWIdwAAACrOB5u8vLylJCQoLCwMHk8Hm3btq3Z/rW1tVq8eLHi4+Pldrt1zjnnaPXq1e1ULQAACHaOvi21bt06LViwQHl5eRo7dqxWrFihiRMnateuXerfv3+T+0ydOlVffvmlVq1apYEDB6qyslJHjx5t58oBAECwcjTc5OTkaPbs2ZozZ44kKTc3Vxs3btTy5cuVnZ3dqP9rr72mrVu36tNPP1WvXr0kSQMGDGjPkgEAQJBz7LFUXV2dioqKlJKSEtCekpKiwsLCJvd56aWXlJSUpAceeEBnnXWWzj33XN1111367rvvTnic2tpa1dTUBCwAAMBejs3cHDhwQPX19YqKigpoj4qKUkVFRZP7fPrpp9q+fbvCwsK0YcMGHThwQOnp6fr6669P+Lmb7OxsLVmypNXrBwAAwcnxDxS7XK6AdWNMo7bjGhoa5HK59Ic//EH/9E//pCuvvFI5OTnKz88/4exNRkaGqqur/Ut5eXmrnwMAAAgejs3c9OnTR507d240S1NZWdloNue4mJgYnXXWWYqMjPS3DR06VMYYff755xo0aFCjfdxut9xud+sWDwAAgpZjMzehoaHyeDzyer0B7V6vV2PGjGlyn7Fjx+qLL77QoUOH/G3/+7//q06dOqlfv35tWi8AAOgYHH0stXDhQj355JNavXq1PvzwQ915550qKytTWlqapGOPlG6++f//+OL06dPVu3dv/cu//It27dqlN954Q3fffbdmzZql8PBwp04DAAAEEUdfBU9NTVVVVZWysrLk8/mUmJiogoICxcfHS5J8Pp/Kysr8/bt27Sqv16vbb79dSUlJ6t27t6ZOnap7773XqVMAAABBxtFwI0np6elKT09vclt+fn6jtiFDhjR6lAUAAHCc429LAQAAtCbCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVHA83eXl5SkhIUFhYmDwej7Zt23bCvlu2bJHL5Wq07N69ux0rBgAAwczRcLNu3TotWLBAixcvVnFxscaNG6eJEyeqrKys2f0++ugj+Xw+/zJo0KB2qhgAAAQ7R8NNTk6OZs+erTlz5mjo0KHKzc1VXFycli9f3ux+ffv2VXR0tH/p3LlzO1UMAACCnWPhpq6uTkVFRUpJSQloT0lJUWFhYbP7jhw5UjExMbr00kv1+uuvt2WZAACggwlx6sAHDhxQfX29oqKiAtqjoqJUUVHR5D4xMTFauXKlPB6Pamtr9fTTT+vSSy/Vli1bdPHFFze5T21trWpra/3rNTU1rXcSAAAg6DgWbo5zuVwB68aYRm3HDR48WIMHD/avJycnq7y8XMuWLTthuMnOztaSJUtar2AAABDUHHss1adPH3Xu3LnRLE1lZWWj2ZzmjB49Wnv27Dnh9oyMDFVXV/uX8vLyn1wzAAAIfo6Fm9DQUHk8Hnm93oB2r9erMWPGtHic4uJixcTEnHC72+1W9+7dAxYAAGAvRx9LLVy4UDNmzFBSUpKSk5O1cuVKlZWVKS0tTdKxWZf9+/dr7dq1kqTc3FwNGDBA559/vurq6vT73/9e69ev1/r16508DQAAEEQcDTepqamqqqpSVlaWfD6fEhMTVVBQoPj4eEmSz+cL+M6buro63XXXXdq/f7/Cw8N1/vnn65VXXtGVV17p1CkAAIAg4/gHitPT05Went7ktvz8/ID1RYsWadGiRe1QFQAA6Kgc//kFAACA1kS4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFjF8XCTl5enhIQEhYWFyePxaNu2bS3a769//atCQkJ0wQUXtG2BAACgQ3E03Kxbt04LFizQ4sWLVVxcrHHjxmnixIkqKytrdr/q6mrdfPPNuvTSS9upUgAA0FE4Gm5ycnI0e/ZszZkzR0OHDlVubq7i4uK0fPnyZvebO3eupk+fruTk5HaqFAAAdBSOhZu6ujoVFRUpJSUloD0lJUWFhYUn3G/NmjX65JNPdM8997ToOLW1taqpqQlYAACAvRwLNwcOHFB9fb2ioqIC2qOiolRRUdHkPnv27NG//du/6Q9/+INCQkJadJzs7GxFRkb6l7i4uFOuHQAABC/HP1DscrkC1o0xjdokqb6+XtOnT9eSJUt07rnntnj8jIwMVVdX+5fy8vJTrhkAAASvlk1/tIE+ffqoc+fOjWZpKisrG83mSNLBgwe1c+dOFRcXa968eZKkhoYGGWMUEhKiTZs26ZJLLmm0n9vtltvtbpuTAAAAQcexmZvQ0FB5PB55vd6Adq/XqzFjxjTq3717d5WWlqqkpMS/pKWlafDgwSopKdGoUaPaq3QAABDEHJu5kaSFCxdqxowZSkpKUnJyslauXKmysjKlpaVJOvZIaf/+/Vq7dq06deqkxMTEgP379u2rsLCwRu0AAOD05Wi4SU1NVVVVlbKysuTz+ZSYmKiCggLFx8dLknw+30m/8wYAAOAfORpuJCk9PV3p6elNbsvPz29238zMTGVmZrZ+UQAAoMNy/G0pAACA1kS4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwSquFm/Lycs2aNau1hgMAAPhJWi3cfP3113rqqadaazgAAICfpMXfUPzSSy81u/3TTz895WIAAABOVYvDzbXXXiuXyyVjzAn7uFyuVikKAADgp2rxY6mYmBitX79eDQ0NTS7vvPNOW9YJAADQIi0ONx6Pp9kAc7JZHQAAgPbQosdS7733nu6++24dPnz4hH0GDhyo119/vdUKAwAA+ClaFG5Gjhwpn8+nvn376uyzz9bbb7+t3r17B/SJiIjQ+PHj26RIAACAlmrRY6kePXpo7969kqR9+/apoaGhTYsCAAD4qVo0c3P99ddr/PjxiomJkcvlUlJSkjp37txkX14JBwAATmpRuFm5cqWuu+46ffzxx5o/f75uvfVWdevWra1rAwAA+NFa/D03V1xxhSSpqKhId9xxB+EGAAAEpRaHm+PWrFnTFnUAAAC0Cn4VHAAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFZxPNzk5eUpISFBYWFh8ng82rZt2wn7bt++XWPHjlXv3r0VHh6uIUOG6KGHHmrHagEAQLALcfLg69at04IFC5SXl6exY8dqxYoVmjhxonbt2qX+/fs36h8REaF58+Zp+PDhioiI0Pbt2zV37lxFREToX//1Xx04AwAAEGwcnbnJycnR7NmzNWfOHA0dOlS5ubmKi4vT8uXLm+w/cuRITZs2Teeff74GDBigm266SRMmTGh2tgcAAJxeHAs3dXV1KioqUkpKSkB7SkqKCgsLWzRGcXGxCgsLNX78+LYoEQAAdECOPZY6cOCA6uvrFRUVFdAeFRWlioqKZvft16+fvvrqKx09elSZmZmaM2fOCfvW1taqtrbWv15TU3NqhQMAgKDm+AeKXS5XwLoxplHbD23btk07d+7UE088odzcXD377LMn7Judna3IyEj/EhcX1yp1AwCA4OTYzE2fPn3UuXPnRrM0lZWVjWZzfighIUGSNGzYMH355ZfKzMzUtGnTmuybkZGhhQsX+tdramoIOAAAWMyxmZvQ0FB5PB55vd6Adq/XqzFjxrR4HGNMwGOnH3K73erevXvAAgAA7OXoq+ALFy7UjBkzlJSUpOTkZK1cuVJlZWVKS0uTdGzWZf/+/Vq7dq0k6fHHH1f//v01ZMgQSce+92bZsmW6/fbbHTsHAAAQXBwNN6mpqaqqqlJWVpZ8Pp8SExNVUFCg+Ph4SZLP51NZWZm/f0NDgzIyMrR3716FhITonHPO0dKlSzV37lynTgEAAAQZR8ONJKWnpys9Pb3Jbfn5+QHrt99+O7M0AACgWY6/LQUAANCaCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqzgebvLy8pSQkKCwsDB5PB5t27bthH1feOEFXX755TrzzDPVvXt3JScna+PGje1YLQAACHaOhpt169ZpwYIFWrx4sYqLizVu3DhNnDhRZWVlTfZ/4403dPnll6ugoEBFRUX6+c9/rkmTJqm4uLidKwcAAMHK0XCTk5Oj2bNna86cORo6dKhyc3MVFxen5cuXN9k/NzdXixYt0kUXXaRBgwbp/vvv16BBg/Tyyy+3c+UAACBYORZu6urqVFRUpJSUlID2lJQUFRYWtmiMhoYGHTx4UL169Tphn9raWtXU1AQsAADAXo6FmwMHDqi+vl5RUVEB7VFRUaqoqGjRGA8++KAOHz6sqVOnnrBPdna2IiMj/UtcXNwp1Q0AAIKb4x8odrlcAevGmEZtTXn22WeVmZmpdevWqW/fvifsl5GRoerqav9SXl5+yjUDAIDgFeLUgfv06aPOnTs3mqWprKxsNJvzQ+vWrdPs2bP1/PPP67LLLmu2r9vtltvtPuV6AQBAx+DYzE1oaKg8Ho+8Xm9Au9fr1ZgxY06437PPPquZM2fqmWee0VVXXdXWZQIAgA7GsZkbSVq4cKFmzJihpKQkJScna+XKlSorK1NaWpqkY4+U9u/fr7Vr10o6FmxuvvlmPfzwwxo9erR/1ic8PFyRkZGOnQcAAAgejoab1NRUVVVVKSsrSz6fT4mJiSooKFB8fLwkyefzBXznzYoVK3T06FHddtttuu222/ztt9xyi/Lz89u7fAAAEIQcDTeSlJ6ervT09Ca3/TCwbNmype0LAgAAHZrjb0sBAAC0JsINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqOh5u8vDwlJCQoLCxMHo9H27ZtO2Ffn8+n6dOna/DgwerUqZMWLFjQfoUCAIAOwdFws27dOi1YsECLFy9WcXGxxo0bp4kTJ6qsrKzJ/rW1tTrzzDO1ePFijRgxop2rBQAAHYGj4SYnJ0ezZ8/WnDlzNHToUOXm5iouLk7Lly9vsv+AAQP08MMP6+abb1ZkZGQ7VwsAADoCx8JNXV2dioqKlJKSEtCekpKiwsLCVjtObW2tampqAhYAAGAvx8LNgQMHVF9fr6ioqID2qKgoVVRUtNpxsrOzFRkZ6V/i4uJabWwAABB8HP9AscvlClg3xjRqOxUZGRmqrq72L+Xl5a02NgAACD4hTh24T58+6ty5c6NZmsrKykazOafC7XbL7Xa32ngAACC4OTZzExoaKo/HI6/XG9Du9Xo1ZswYh6oCAAAdnWMzN5K0cOFCzZgxQ0lJSUpOTtbKlStVVlamtLQ0ScceKe3fv19r167171NSUiJJOnTokL766iuVlJQoNDRU5513nhOnAAAAgoyj4SY1NVVVVVXKysqSz+dTYmKiCgoKFB8fL+nYl/b98DtvRo4c6f/fRUVFeuaZZxQfH699+/a1Z+kAACBIORpuJCk9PV3p6elNbsvPz2/UZoxp44oAAEBH5vjbUgAAAK2JcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcfDTV5enhISEhQWFiaPx6Nt27Y123/r1q3yeDwKCwvT2WefrSeeeKKdKgUAAB2Bo+Fm3bp1WrBggRYvXqzi4mKNGzdOEydOVFlZWZP99+7dqyuvvFLjxo1TcXGxfvvb32r+/Plav359O1cOAACClaPhJicnR7Nnz9acOXM0dOhQ5ebmKi4uTsuXL2+y/xNPPKH+/fsrNzdXQ4cO1Zw5czRr1iwtW7asnSsHAADByrFwU1dXp6KiIqWkpAS0p6SkqLCwsMl9duzY0aj/hAkTtHPnTh05cqTNagUAAB1HiFMHPnDggOrr6xUVFRXQHhUVpYqKiib3qaioaLL/0aNHdeDAAcXExDTap7a2VrW1tf716upqSVJNTc1Ja6yv/e6kfXBiLbnGP8bB7+tbdbzTSWvfi6PfHW3V8U4nrX0vDh/lXvxUrX0vvqv9e6uOdzppyb043scYc9K+joWb41wuV8C6MaZR28n6N9V+XHZ2tpYsWdKoPS4u7seWih8p8tE0p0vAcdmRTleA/yfyN9yLoBHJvQgWix5ved+DBw8q8iT3zrFw06dPH3Xu3LnRLE1lZWWj2ZnjoqOjm+wfEhKi3r17N7lPRkaGFi5c6F9vaGjQ119/rd69ezcbooJdTU2N4uLiVF5eru7duztdzmmNexE8uBfBhfsRPGy4F8YYHTx4ULGxsSft61i4CQ0Nlcfjkdfr1ZQpU/ztXq9XkydPbnKf5ORkvfzyywFtmzZtUlJSkrp06dLkPm63W263O6CtR48ep1Z8EOnevXuH/Q/VNtyL4MG9CC7cj+DR0e/FyWZsjnP0bamFCxfqySef1OrVq/Xhhx/qzjvvVFlZmdLSjj3OyMjI0M033+zvn5aWps8++0wLFy7Uhx9+qNWrV2vVqlW66667nDoFAAAQZBz9zE1qaqqqqqqUlZUln8+nxMREFRQUKD4+XpLk8/kCvvMmISFBBQUFuvPOO/X4448rNjZWjzzyiK6//nqnTgEAAAQZxz9QnJ6ervT09Ca35efnN2obP3683nnnnTauKvi53W7dc889jR65of1xL4IH9yK4cD+Cx+l2L1ymJe9UAQAAdBCO/7YUAABAayLcAAAAqxBuAACAVQg3DnrjjTc0adIkxcbGyuVy6cUXXwzYboxRZmamYmNjFR4erp/97Gf64IMPAvrU1tbq9ttvV58+fRQREaFrrrlGn3/+eUCfb775RjNmzFBkZKQiIyM1Y8YMffvtt218dsEtmK59WVmZJk2apIiICPXp00fz589XXV1dW5x20MnMzJTL5QpYoqOj/du5D22ro/05KC0t1fjx4xUeHq6zzjpLWVlZLfoq/mC3fPlyDR8+3P8dNMnJyXr11Vf92zMzMzVkyBBFRESoZ8+euuyyy/TWW28FjDF37lydc845Cg8P15lnnqnJkydr9+7dTR6vtrZWF1xwgVwul0pKSgK23XHHHfJ4PHK73brggguarfvjjz9Wt27dgvK74wg3Djp8+LBGjBihxx57rMntDzzwgHJycvTYY4/p7bffVnR0tC6//HIdPHjQ32fBggXasGGDnnvuOW3fvl2HDh3S1Vdfrfr6//87TNOnT1dJSYlee+01vfbaayopKdGMGTPa/PyCWbBc+/r6el111VU6fPiwtm/frueee07r16/Xr3/967Y7+SBz/vnny+fz+ZfS0lL/Nu5D2+pIfw5qamp0+eWXKzY2Vm+//bYeffRRLVu2TDk5OW1wZdpXv379tHTpUu3cuVM7d+7UJZdcosmTJ/uD5LnnnqvHHntMpaWl2r59uwYMGKCUlBR99dVX/jE8Ho/WrFmjDz/8UBs3bpQxRikpKQH34bhFixad8Ft+jTGaNWuWUlNTm635yJEjmjZtmsaNG3cKZ96GDIKCJLNhwwb/ekNDg4mOjjZLly71t33//fcmMjLSPPHEE8YYY7799lvTpUsX89xzz/n77N+/33Tq1Mm89tprxhhjdu3aZSSZN998099nx44dRpLZvXt3G59Vx+DktS8oKDCdOnUy+/fv9/d59tlnjdvtNtXV1W1yvsHknnvuMSNGjGhyG/ehfQX7n4O8vDwTGRlpvv/+e3+f7OxsExsbaxoaGlrxSgSHnj17mieffLLJbdXV1UaS2bx58wn3f/fdd40k8/HHHwe0FxQUmCFDhpgPPvjASDLFxcVN7t/cn01jjFm0aJG56aabzJo1a0xkZOTJTqfdMXMTpPbu3auKigqlpKT429xut8aPH6/CwkJJUlFRkY4cORLQJzY2VomJif4+O3bsUGRkpEaNGuXvM3r0aEVGRvr7IFB7XvsdO3YoMTEx4F9REyZMUG1trYqKitr0PIPFnj17FBsbq4SEBP3yl7/Up59+Kon74LRgu/47duzQ+PHjA76nZcKECfriiy+0b9++1r8ADqmvr9dzzz2nw4cPKzk5udH2uro6rVy5UpGRkRoxYkSTYxw+fFhr1qxRQkJCwI9Ef/nll7r11lv19NNP64wzzvjJNf7lL3/R888/r8cf/xG/dtnOCDdB6vgPhP7wR0SjoqL82yoqKhQaGqqePXs226dv376Nxu/bt2+jHyHFMe157SsqKhodp2fPngoNDT0t7s+oUaO0du1abdy4Ub/73e9UUVGhMWPGqKqqivvgsGC7/k31Ob5uwz0qLS1V165d5Xa7lZaWpg0bNui8887zb//Tn/6krl27KiwsTA899JC8Xq/69OkTMEZeXp66du2qrl276rXXXpPX61VoaKikY4+bZs6cqbS0NCUlJf3kOquqqjRz5kzl5+cH9W9UEW6C3A9/udwYc9JfM/9hn6b6t2Sc0117XfvT+f5MnDhR119/vYYNG6bLLrtMr7zyiiTpqaee8vfhPjgrmK5/U7WcaN+OZvDgwSopKdGbb76pX/3qV7rlllu0a9cu//af//znKikpUWFhoa644gpNnTpVlZWVAWPceOONKi4u1tatWzVo0CBNnTpV33//vSTp0UcfVU1NjTIyMk6pzltvvVXTp0/XxRdffErjtDXCTZA6/sbID/9FUllZ6f/XSnR0tOrq6vTNN9802+fLL79sNP5XX33V6F9BOKY9r310dHSj43zzzTc6cuTIaXl/IiIiNGzYMO3Zs4f74LBgu/5N9Tn+l7sN9yg0NFQDBw5UUlKSsrOzNWLECD388MP+7RERERo4cKBGjx6tVatWKSQkRKtWrQoYIzIyUoMGDdLFF1+sP/7xj9q9e7c2bNgg6dijpDfffFNut1shISEaOHCgJCkpKUm33HJLi+v8y1/+omXLlikkJEQhISGaPXu2qqurFRISotWrV7fClWgdhJsglZCQoOjoaHm9Xn9bXV2dtm7dqjFjxkg69un4Ll26BPTx+Xx6//33/X2Sk5NVXV2tv/3tb/4+b731lqqrq/19EKg9r31ycrLef/99+Xw+f59NmzbJ7XbL4/G06XkGo9raWn344YeKiYnhPjgs2K5/cnKy3njjjYDXwzdt2qTY2FgNGDCg9S+Aw4wxqq2t/cnbf9jnkUce0bvvvquSkhKVlJSooKBAkrRu3Trdd999La5rx44d/jFKSkqUlZWlbt26qaSkRFOmTGnxOG2ufT+/jH908OBBU1xcbIqLi40kk5OTY4qLi81nn31mjDFm6dKlJjIy0rzwwgumtLTUTJs2zcTExJiamhr/GGlpaaZfv35m8+bN5p133jGXXHKJGTFihDl69Ki/zxVXXGGGDx9uduzYYXbs2GGGDRtmrr766nY/32ASLNf+6NGjJjEx0Vx66aXmnXfeMZs3bzb9+vUz8+bNa7+L4aBf//rXZsuWLebTTz81b775prn66qtNt27dzL59+4wx3Ie21pH+HHz77bcmKirKTJs2zZSWlpoXXnjBdO/e3SxbtqwdrlTbysjIMG+88YbZu3evee+998xvf/tb06lTJ7Np0yZz6NAhk5GRYXbs2GH27dtnioqKzOzZs43b7Tbvv/++McaYTz75xNx///1m586d5rPPPjOFhYVm8uTJplevXubLL79s8ph79+5t8m2pPXv2mOLiYjN37lxz7rnn+v/7qK2tbXKcYH1binDjoNdff91IarTccsstxphjr2Lec889Jjo62rjdbnPxxReb0tLSgDG+++47M2/ePNOrVy8THh5urr76alNWVhbQp6qqytx4442mW7duplu3bubGG28033zzTTudZXAKpmv/2WefmauuusqEh4ebXr16mXnz5gW87mqz1NRUExMTY7p06WJiY2PNddddZz744AP/du5D2+pofw7ee+89M27cOON2u010dLTJzMy04jXwWbNmmfj4eBMaGmrOPPNMc+mll5pNmzYZY45d3ylTppjY2FgTGhpqYmJizDXXXGP+9re/+fffv3+/mThxounbt6/p0qWL6devn5k+fXqzX/dxonAzfvz4Jv+b2Lt3b5PjBGu44VfBAQCAVfjMDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINgKD1s5/9TAsWLHC6DAAdDN9QDCBoff311+rSpYu6devWKuO5XC5t2LBB1157bauMByA4hThdAACcSK9evZwuAUAHxGMpAJKOPQKaP3++Fi1apF69eik6OlqZmZmSpH379snlcqmkpMTf/9tvv5XL5dKWLVskSVu2bJHL5dLGjRs1cuRIhYeH65JLLlFlZaVeffVVDR06VN27d9e0adP097//vcU1/eNjqQEDBuj+++/XrFmz1K1bN/Xv318rV670b6+rq9O8efMUExOjsLAwDRgwQNnZ2f59JWnKlClyuVz+9U8++USTJ09WVFSUunbtqosuukibN28OqONkx5Wkzz//XL/85S/Vq1cvRUREKCkpSW+99ZZ/+8svvyyPx6OwsDCdffbZWrJkiY4ePerfnpmZqf79+8vtdis2Nlbz589v0TUC0BjhBoDfU089pYiICL311lt64IEHlJWVJa/X+6PGyMzM1GOPPabCwkKVl5dr6tSpys3N1TPPPKNXXnlFXq9Xjz766E+u8cEHH1RSUpKKi4uVnp6uX/3qV9q9e7ck6ZFHHtFLL72k//mf/9FHH32k3//+9/4Q8/bbb0uS1qxZI5/P518/dOiQrrzySm3evFnFxcWaMGGCJk2apLKyshYf99ChQxo/fry++OILvfTSS3r33Xe1aNEiNTQ0SJI2btyom266SfPnz9euXbu0YsUK5efn67777pMk/fGPf9RDDz2kFStWaM+ePXrxxRc1bNiwn3yNgNOesz9KDiBYjB8/3vzzP/9zQNtFF11kfvOb35i9e/caSaa4uNi/7ZtvvjGSzOuvv26MMeb11183kszmzZv9fbKzs40k88knn/jb5s6dayZMmNDimu644w7/enx8vLnpppv86w0NDaZv375m+fLlxhhjbr/9dnPJJZeYhoaGJseTZDZs2HDS45533nnm0UcfbfFxV6xYYbp162aqqqqaHG/cuHHm/vvvD2h7+umnTUxMjDHGmAcffNCce+65pq6u7qS1ATg5Zm4A+A0fPjxgPSYmRpWVlT95jKioKJ1xxhk6++yzA9p+7JgnGt/lcik6Oto/3syZM1VSUqLBgwdr/vz52rRp00nHO3z4sBYtWqTzzjtPPXr0UNeuXbV79+5GMzfNHbekpEQjR4484WeEioqKlJWVpa5du/qXW2+9VT6fT3//+991ww036LvvvtPZZ5+tW2+9VRs2bAh4ZAXgxyHcAPDr0qVLwLrL5VJDQ4M6dTr2fxXmH16uPHLkyEnHcLlcJxyztWuUpAsvvFB79+7Vf/3Xf+m7777T1KlT9Ytf/KLZ8e6++26tX79e9913n7Zt26aSkhINGzZMdXV1LT5ueHh4s8doaGjQkiVLVFJS4l9KS0u1Z88ehYWFKS4uTh999JEef/xxhYeHKz09XRdffPEJrzGA5vG2FICTOvPMMyVJPp9PI0eOlKSADxcHk+7duys1NVWpqan6xS9+oSuuuEJff/21evXqpS5duqi+vj6g/7Zt2zRz5kxNmTJF0rHPz+zbt+9HHXP48OF68skn/cf5oQsvvFAfffSRBg4ceMIxwsPDdc011+iaa67RbbfdpiFDhqi0tFQXXnjhj6oFAOEGQAuEh4dr9OjRWrp0qQYMGKADBw7o3//9350uq5GHHnpIMTExuuCCC9SpUyc9//zzio6OVo8ePSQde+vpz3/+s8aOHSu3262ePXtq4MCBeuGFFzRp0iS5XC79x3/8x4+eWZo2bZruv/9+XXvttcrOzlZMTIyKi4sVGxur5ORk/ed//qeuvvpqxcXF6YYbblCnTp303nvvqbS0VPfee6/y8/NVX1+vUaNG6YwzztDTTz+t8PBwxcfHt8FVAuzHYykALbJ69WodOXJESUlJuuOOO3Tvvfc6XVIjXbt21X//938rKSlJF110kfbt26eCggL/Y7UHH3xQXq9XcXFx/hmohx56SD179tSYMWM0adIkTZgw4UfPloSGhmrTpk3q27evrrzySg0bNkxLly5V586dJUkTJkzQn/70J3m9Xl100UUaPXq0cnJy/OGlR48e+t3vfqexY8dq+PDh+vOf/6yXX35ZvXv3bsWrA5w++IZiAABgFWZuAACAVQg3ABxRVlYW8Gr0D5cfvooNAC3FYykAjjh69GizbyUNGDBAISG88wDgxyPcAAAAq/BYCgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwyv8FYBn1dHzI6oAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(performace_f1_scores)\n",
    "\n",
    "df = pd.DataFrame({'num_instances': training_sizes, 'f1': performace_f1_scores})\n",
    "sns.barplot(data=df, x='num_instances', y='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a uni, bi, and trigram vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333414, 23797)\n"
     ]
    }
   ],
   "source": [
    "trigram_vectorizer = TfidfVectorizer(stop_words='english', min_df=25, ngram_range=(1,3))\n",
    "X_train = trigram_vectorizer.fit_transform(train_df.original_text)\n",
    "print(X_train.shape)\n",
    "clf = LogisticRegression(random_state=RANDOM_SEED, multi_class='ovr', solver= 'newton-cg')\n",
    "clf.fit(X_train, y_train)\n",
    "#featurize the dev data\n",
    "X_dev = trigram_vectorizer.transform(dev_df.original_text)\n",
    "#predict the dev data and score\n",
    "lr_trigram_dev_preds = clf.predict(X_dev)\n",
    "lr_f1 = f1_score(y_dev, lr_trigram_dev_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6879448653584948\n"
     ]
    }
   ],
   "source": [
    "print(lr_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_df @ 500, ngram_range(1,3), multi_class='ovr', solver = 'newton-cholesky' (didn't take too long) scored 0.6451618658\n",
    "min_df @  25, ngram_range(1,3), multi_class='ovr', solver = 'newton-cholesky' (6m 19.1s) scored 0.6880169450552442"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the Dale Chall text - into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'able', 'aboard', 'about', 'above ']\n"
     ]
    }
   ],
   "source": [
    "dc_text = open(r'assets/dale_chall.txt', \"r\")\n",
    "dalechall_file = dc_text.read()\n",
    "# split text on new line\n",
    "dalechall_list = dalechall_file.split('\\n')\n",
    "print(dalechall_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2950"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dalechall_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !pip install spacy_syllables\n",
    "# !python -m spacy download en_core_web_lg\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy_syllables import SpacySyllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_syllables.SpacySyllables at 0x7faaeec3e4f0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using https://spacy.io/universe/project/spacy_syllables\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.add_pipe(\"syllables\", after=\"tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m WikiLarge_Train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_characters\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m WikiLarge_Train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mog_split\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28msum\u001b[39m([\u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m x]))\n\u001b[1;32m      8\u001b[0m WikiLarge_Train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msyl_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m WikiLarge_Train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [token\u001b[38;5;241m.\u001b[39m_\u001b[38;5;241m.\u001b[39msyllables_count \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m nlp(x)])\n\u001b[0;32m----> 9\u001b[0m WikiLarge_Train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_syllables\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mWikiLarge_Train_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msyl_list\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m WikiLarge_Train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_polysyllables\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m WikiLarge_Train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msyl_list\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28msum\u001b[39m([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m     13\u001b[0m WikiLarge_Train_df\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[60], line 9\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m WikiLarge_Train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_characters\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m WikiLarge_Train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mog_split\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28msum\u001b[39m([\u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m x]))\n\u001b[1;32m      8\u001b[0m WikiLarge_Train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msyl_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m WikiLarge_Train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [token\u001b[38;5;241m.\u001b[39m_\u001b[38;5;241m.\u001b[39msyllables_count \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m nlp(x)])\n\u001b[0;32m----> 9\u001b[0m WikiLarge_Train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_syllables\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m WikiLarge_Train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msyl_list\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m WikiLarge_Train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_polysyllables\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m WikiLarge_Train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msyl_list\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28msum\u001b[39m([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m     13\u001b[0m WikiLarge_Train_df\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "split_pat = re.compile(r'\\b\\s+\\b')\n",
    "\n",
    "WikiLarge_Train_df['og_split'] = WikiLarge_Train_df['original_text'].apply(lambda x: re.split(split_pat, x))\n",
    "WikiLarge_Train_df['total_words'] = WikiLarge_Train_df['og_split'].apply(lambda x: len(x))\n",
    "WikiLarge_Train_df['long_words'] = WikiLarge_Train_df['og_split'].apply(lambda x: len([y for y in x if len(y) > 7]))\n",
    "WikiLarge_Train_df['total_sentences'] = 1\n",
    "WikiLarge_Train_df['total_characters'] = WikiLarge_Train_df['og_split'].apply(lambda x: sum([len(y) for y in x]))\n",
    "WikiLarge_Train_df['syl_list'] = WikiLarge_Train_df['original_text'].apply(lambda x: [token._.syllables_count for token in nlp(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>parsed_list</th>\n",
       "      <th>All_Characters</th>\n",
       "      <th>Is_Int</th>\n",
       "      <th>total_words</th>\n",
       "      <th>og_split</th>\n",
       "      <th>long_words</th>\n",
       "      <th>total_sentences</th>\n",
       "      <th>total_characters</th>\n",
       "      <th>syl_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[There,  , is,  , manuscript,  , evidence,  , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>[There, is, manuscript, evidence, that, Austen...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>[1, 1, 3, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "      <td>[In,  , a,  , remarkable,  , comparative,  , a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>[In, a, remarkable, comparative, analysis , Ma...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>[1, 1, 3, 4, 3, None, 2, 2, 1, None, 2, 3, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Before,  , Persephone,  , was,  , released,  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>[Before, Persephone, was, released, to, Hermes...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>213</td>\n",
       "      <td>[2, 2, 1, 2, 1, 2, None, 1, 1, 1, 1, 1, 2, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Cogeneration,  , plants,  , are,  , commonly,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>[Cogeneration, plants, are, commonly, found, i...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>221</td>\n",
       "      <td>[5, 1, 1, 3, 1, 1, 2, 2, 2, 1, 1, None, 3, Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Geneva,  , -LRB-,  , ,,  , ;,  , ,,  , ;,  , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>[Geneva -LRB- , ; , ; , ; ; -RRB- is, the, sec...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>[2, None, None, None, None, None, None, None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416763</th>\n",
       "      <td>A Duke Nukem 3D version has been sold for Xbox...</td>\n",
       "      <td>0</td>\n",
       "      <td>[A,  , Duke,  , Nukem,  , 3D,  , version,  , h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>[A, Duke, Nukem, 3D, version, has, been, sold,...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>[1, 1, 1, None, 2, 1, 1, 1, 1, 1, 1, 1, 3, Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416764</th>\n",
       "      <td>However , it is becoming replaced as a method ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[However,  , ,,  , it,  , is,  , becoming,  , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>[However , it, is, becoming, replaced, as, a, ...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>[3, None, 1, 1, 3, 2, 1, 1, 1, 1, 4, 3, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416765</th>\n",
       "      <td>There are hand gestures in both Hindu and Budd...</td>\n",
       "      <td>0</td>\n",
       "      <td>[There,  , are,  , hand,  , gestures,  , in,  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[There, are, hand, gestures, in, both, Hindu, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>[1, 1, 1, 2, 1, 1, 2, 1, 2, 3, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416766</th>\n",
       "      <td>If it is necessary to use colors , try to choo...</td>\n",
       "      <td>0</td>\n",
       "      <td>[If,  , it,  , is,  , necessary,  , to,  , use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>[If, it, is, necessary, to, use, colors , try,...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "      <td>[1, 1, 1, 3, 1, 1, 2, None, 1, 1, 1, 2, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416767</th>\n",
       "      <td>Calgary Stampeders ,</td>\n",
       "      <td>0</td>\n",
       "      <td>[Calgary,  , Stampeders,  , ,]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Calgary, Stampeders ,]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>[2, 3, None]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416768 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  label                                        parsed_list  All_Characters  Is_Int  \\\n",
       "0       There is manuscript evidence that Austen conti...      1  [There,  , is,  , manuscript,  , evidence,  , ...               0       0   \n",
       "1       In a remarkable comparative analysis , Mandaea...      1  [In,  , a,  , remarkable,  , comparative,  , a...               0       0   \n",
       "2       Before Persephone was released to Hermes , who...      1  [Before,  , Persephone,  , was,  , released,  ...               0       0   \n",
       "3       Cogeneration plants are commonly found in dist...      1  [Cogeneration,  , plants,  , are,  , commonly,...               0       0   \n",
       "4       Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1  [Geneva,  , -LRB-,  , ,,  , ;,  , ,,  , ;,  , ...               0       0   \n",
       "...                                                   ...    ...                                                ...             ...     ...   \n",
       "416763  A Duke Nukem 3D version has been sold for Xbox...      0  [A,  , Duke,  , Nukem,  , 3D,  , version,  , h...               0       0   \n",
       "416764  However , it is becoming replaced as a method ...      0  [However,  , ,,  , it,  , is,  , becoming,  , ...               0       0   \n",
       "416765  There are hand gestures in both Hindu and Budd...      0  [There,  , are,  , hand,  , gestures,  , in,  ...               0       0   \n",
       "416766  If it is necessary to use colors , try to choo...      0  [If,  , it,  , is,  , necessary,  , to,  , use...               0       0   \n",
       "416767                               Calgary Stampeders ,      0                     [Calgary,  , Stampeders,  , ,]               0       0   \n",
       "\n",
       "        total_words                                           og_split  long_words  total_sentences  total_characters  \\\n",
       "0                34  [There, is, manuscript, evidence, that, Austen...           7                1               182   \n",
       "1                19  [In, a, remarkable, comparative, analysis , Ma...           6                1               136   \n",
       "2                36  [Before, Persephone, was, released, to, Hermes...          10                1               213   \n",
       "3                26  [Cogeneration, plants, are, commonly, found, i...          11                1               221   \n",
       "4                18  [Geneva -LRB- , ; , ; , ; ; -RRB- is, the, sec...           8                1               184   \n",
       "...             ...                                                ...         ...              ...               ...   \n",
       "416763           14  [A, Duke, Nukem, 3D, version, has, been, sold,...           2                1                66   \n",
       "416764           17  [However , it, is, becoming, replaced, as, a, ...           6                1                95   \n",
       "416765           10  [There, are, hand, gestures, in, both, Hindu, ...           3                1                55   \n",
       "416766           34  [If, it, is, necessary, to, use, colors , try,...           7                1               183   \n",
       "416767            2                            [Calgary, Stampeders ,]           1                1                19   \n",
       "\n",
       "                                                 syl_list  \n",
       "0       [1, 1, 3, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1       [1, 1, 3, 4, 3, None, 2, 2, 1, None, 2, 3, 1, ...  \n",
       "2       [2, 2, 1, 2, 1, 2, None, 1, 1, 1, 1, 1, 2, 1, ...  \n",
       "3       [5, 1, 1, 3, 1, 1, 2, 2, 2, 1, 1, None, 3, Non...  \n",
       "4       [2, None, None, None, None, None, None, None, ...  \n",
       "...                                                   ...  \n",
       "416763  [1, 1, 1, None, 2, 1, 1, 1, 1, 1, 1, 1, 3, Non...  \n",
       "416764  [3, None, 1, 1, 3, 2, 1, 1, 1, 1, 4, 3, 1, 1, ...  \n",
       "416765               [1, 1, 1, 2, 1, 1, 2, 1, 2, 3, None]  \n",
       "416766  [1, 1, 1, 3, 1, 1, 2, None, 1, 1, 1, 2, 1, 1, ...  \n",
       "416767                                       [2, 3, None]  \n",
       "\n",
       "[416768 rows x 11 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WikiLarge_Train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>parsed_list</th>\n",
       "      <th>All_Characters</th>\n",
       "      <th>Is_Int</th>\n",
       "      <th>total_words</th>\n",
       "      <th>og_split</th>\n",
       "      <th>long_words</th>\n",
       "      <th>total_sentences</th>\n",
       "      <th>total_characters</th>\n",
       "      <th>syl_list</th>\n",
       "      <th>total_syllables</th>\n",
       "      <th>total_polysyllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[There,  , is,  , manuscript,  , evidence,  , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>[There, is, manuscript, evidence, that, Austen...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>[1, 1, 3, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "      <td>[In,  , a,  , remarkable,  , comparative,  , a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>[In, a, remarkable, comparative, analysis , Ma...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>[1, 1, 3, 4, 3, 2, 2, 1, 2, 3, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Before,  , Persephone,  , was,  , released,  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>[Before, Persephone, was, released, to, Hermes...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>213</td>\n",
       "      <td>[2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, ...</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Cogeneration,  , plants,  , are,  , commonly,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>[Cogeneration, plants, are, commonly, found, i...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>221</td>\n",
       "      <td>[5, 1, 1, 3, 1, 1, 2, 2, 2, 1, 1, 3, 2, 1, 3, ...</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Geneva,  , -LRB-,  , ,,  , ;,  , ,,  , ;,  , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>[Geneva -LRB- , ; , ; , ; ; -RRB- is, the, sec...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>[2, 1, 1, 2, 1, 3, 1, 1, 2, 2, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416763</th>\n",
       "      <td>A Duke Nukem 3D version has been sold for Xbox...</td>\n",
       "      <td>0</td>\n",
       "      <td>[A,  , Duke,  , Nukem,  , 3D,  , version,  , h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>[A, Duke, Nukem, 3D, version, has, been, sold,...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>[1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416764</th>\n",
       "      <td>However , it is becoming replaced as a method ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[However,  , ,,  , it,  , is,  , becoming,  , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>[However , it, is, becoming, replaced, as, a, ...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>[3, 1, 1, 3, 2, 1, 1, 1, 1, 4, 3, 1, 1, 2, 1, ...</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416765</th>\n",
       "      <td>There are hand gestures in both Hindu and Budd...</td>\n",
       "      <td>0</td>\n",
       "      <td>[There,  , are,  , hand,  , gestures,  , in,  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[There, are, hand, gestures, in, both, Hindu, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>[1, 1, 1, 2, 1, 1, 2, 1, 2, 3]</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416766</th>\n",
       "      <td>If it is necessary to use colors , try to choo...</td>\n",
       "      <td>0</td>\n",
       "      <td>[If,  , it,  , is,  , necessary,  , to,  , use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>[If, it, is, necessary, to, use, colors , try,...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "      <td>[1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, ...</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416767</th>\n",
       "      <td>Calgary Stampeders ,</td>\n",
       "      <td>0</td>\n",
       "      <td>[Calgary,  , Stampeders,  , ,]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Calgary, Stampeders ,]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416768 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  label                                        parsed_list  All_Characters  Is_Int  \\\n",
       "0       There is manuscript evidence that Austen conti...      1  [There,  , is,  , manuscript,  , evidence,  , ...               0       0   \n",
       "1       In a remarkable comparative analysis , Mandaea...      1  [In,  , a,  , remarkable,  , comparative,  , a...               0       0   \n",
       "2       Before Persephone was released to Hermes , who...      1  [Before,  , Persephone,  , was,  , released,  ...               0       0   \n",
       "3       Cogeneration plants are commonly found in dist...      1  [Cogeneration,  , plants,  , are,  , commonly,...               0       0   \n",
       "4       Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1  [Geneva,  , -LRB-,  , ,,  , ;,  , ,,  , ;,  , ...               0       0   \n",
       "...                                                   ...    ...                                                ...             ...     ...   \n",
       "416763  A Duke Nukem 3D version has been sold for Xbox...      0  [A,  , Duke,  , Nukem,  , 3D,  , version,  , h...               0       0   \n",
       "416764  However , it is becoming replaced as a method ...      0  [However,  , ,,  , it,  , is,  , becoming,  , ...               0       0   \n",
       "416765  There are hand gestures in both Hindu and Budd...      0  [There,  , are,  , hand,  , gestures,  , in,  ...               0       0   \n",
       "416766  If it is necessary to use colors , try to choo...      0  [If,  , it,  , is,  , necessary,  , to,  , use...               0       0   \n",
       "416767                               Calgary Stampeders ,      0                     [Calgary,  , Stampeders,  , ,]               0       0   \n",
       "\n",
       "        total_words                                           og_split  long_words  total_sentences  total_characters  \\\n",
       "0                34  [There, is, manuscript, evidence, that, Austen...           7                1               182   \n",
       "1                19  [In, a, remarkable, comparative, analysis , Ma...           6                1               136   \n",
       "2                36  [Before, Persephone, was, released, to, Hermes...          10                1               213   \n",
       "3                26  [Cogeneration, plants, are, commonly, found, i...          11                1               221   \n",
       "4                18  [Geneva -LRB- , ; , ; , ; ; -RRB- is, the, sec...           8                1               184   \n",
       "...             ...                                                ...         ...              ...               ...   \n",
       "416763           14  [A, Duke, Nukem, 3D, version, has, been, sold,...           2                1                66   \n",
       "416764           17  [However , it, is, becoming, replaced, as, a, ...           6                1                95   \n",
       "416765           10  [There, are, hand, gestures, in, both, Hindu, ...           3                1                55   \n",
       "416766           34  [If, it, is, necessary, to, use, colors , try,...           7                1               183   \n",
       "416767            2                            [Calgary, Stampeders ,]           1                1                19   \n",
       "\n",
       "                                                 syl_list  total_syllables  total_polysyllables  \n",
       "0       [1, 1, 3, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, ...               48                    5  \n",
       "1       [1, 1, 3, 4, 3, 2, 2, 1, 2, 3, 1, 1, 1, 1, 1, ...               37                    5  \n",
       "2       [2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, ...               56                    4  \n",
       "3       [5, 1, 1, 3, 1, 1, 2, 2, 2, 1, 1, 3, 2, 1, 3, ...               57                    6  \n",
       "4       [2, 1, 1, 2, 1, 3, 1, 1, 2, 2, 1, 1, 1, 1, 1, ...               36                    2  \n",
       "...                                                   ...              ...                  ...  \n",
       "416763               [1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3]               15                    1  \n",
       "416764  [3, 1, 1, 3, 2, 1, 1, 1, 1, 4, 3, 1, 1, 2, 1, ...               31                    5  \n",
       "416765                     [1, 1, 1, 2, 1, 1, 2, 1, 2, 3]               15                    1  \n",
       "416766  [1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, ...               53                    3  \n",
       "416767                                             [2, 3]                5                    1  \n",
       "\n",
       "[416768 rows x 13 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WikiLarge_Train_df['syl_list'] = WikiLarge_Train_df['syl_list'].apply(lambda x: [y for y in x if y is not None])\n",
    "WikiLarge_Train_df['total_syllables'] = WikiLarge_Train_df['syl_list'].apply(lambda x: sum(x))\n",
    "WikiLarge_Train_df['total_polysyllables'] = WikiLarge_Train_df['syl_list'].apply(lambda x: sum([1 for y in x if y>2]))\n",
    "\n",
    "\n",
    "WikiLarge_Train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "WikiLarge_Train_df['total_unique_words'] = WikiLarge_Train_df['og_split'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_calculated = ['total_words', 'long_words', 'total_sentences', 'total_characters', 'syl_list', 'total_syllables', 'total_polysyllables', 'total_unique_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "WikiLarge_Train_df[base_calculated].to_csv('assets/base_calculations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "WikiLarge_Train_df['og_split'].to_csv('assets/bsb_token_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lha assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         293.6\n",
       "1         247.6\n",
       "2         414.4\n",
       "3         450.4\n",
       "4         327.2\n",
       "          ...  \n",
       "416763     85.6\n",
       "416764    246.8\n",
       "416765    124.0\n",
       "416766    293.6\n",
       "416767     40.8\n",
       "Name: gfi, Length: 416768, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# esitmates the years of formal education a person needs to understand the tet on first reading.\n",
    "WikiLarge_Train_df['gfi'] = 0.4 * (WikiLarge_Train_df['total_words'] + 100 * WikiLarge_Train_df['long_words'])\n",
    "WikiLarge_Train_df['gfi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          52.889706\n",
       "1          22.802632\n",
       "2          38.695000\n",
       "3          -5.024231\n",
       "4          19.365000\n",
       "             ...    \n",
       "416763    101.982143\n",
       "416764     35.309412\n",
       "416765     69.785000\n",
       "416766     40.448529\n",
       "416767     -6.695000\n",
       "Name: fre, Length: 416768, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FRE ( Flesch reading ease) assigns higher values to more readable texts.\n",
    "WikiLarge_Train_df['fre'] = 206.835 - 1.015*(WikiLarge_Train_df['total_words']) - 84.6 * (WikiLarge_Train_df['total_syllables']/WikiLarge_Train_df['total_words'])\n",
    "WikiLarge_Train_df['fre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         14.328824\n",
       "1         14.798947\n",
       "2         16.805556\n",
       "3         20.419231\n",
       "4         15.030000\n",
       "            ...    \n",
       "416763     2.512857\n",
       "416764    12.557647\n",
       "416765     6.010000\n",
       "416766    16.064118\n",
       "416767    14.690000\n",
       "Name: fkgl, Length: 416768, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (FKGL) Flesch-Kincaid grade level is the number of years of education generally required to understand the text for which the formula was calculated\n",
    "WikiLarge_Train_df['fkgl'] = 0.39 * (WikiLarge_Train_df['total_words']) + 11.8 * (WikiLarge_Train_df['total_syllables']/WikiLarge_Train_df['total_words']) - 15.59\n",
    "WikiLarge_Train_df['fkgl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         20.782353\n",
       "1         21.783684\n",
       "2         24.437500\n",
       "3         31.605000\n",
       "4         35.716667\n",
       "            ...    \n",
       "416763     7.774286\n",
       "416764    13.390588\n",
       "416765     9.475000\n",
       "416766    20.920882\n",
       "416767    24.315000\n",
       "Name: ari, Length: 416768, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ARI (Automated readability index) years of education required to understand the text\n",
    "WikiLarge_Train_df['ari'] = 4.71 * (WikiLarge_Train_df['total_characters'] / WikiLarge_Train_df['total_words']) + 0.5 * (WikiLarge_Train_df['total_words']) - 21.43\n",
    "WikiLarge_Train_df['ari']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         15.903189\n",
       "1         15.903189\n",
       "2         14.554593\n",
       "3         17.122413\n",
       "4         11.208143\n",
       "            ...    \n",
       "416763     8.841846\n",
       "416764    15.903189\n",
       "416765     8.841846\n",
       "416766    13.023867\n",
       "416767     8.841846\n",
       "Name: smog, Length: 416768, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOG (simple measurement of Gobbledygook) roughly corresponds to the number of years of education needed to understand the text\n",
    "WikiLarge_Train_df['smog'] = 1.0430 * np.sqrt(WikiLarge_Train_df['total_polysyllables'] * 30) + 3.1291\n",
    "WikiLarge_Train_df['smog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.823529\n",
       "1         1.000000\n",
       "2         0.833333\n",
       "3         0.923077\n",
       "4         0.833333\n",
       "            ...   \n",
       "416763    1.000000\n",
       "416764    1.000000\n",
       "416765    1.000000\n",
       "416766    0.852941\n",
       "416767    1.000000\n",
       "Name: ttr, Length: 416768, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TTR (Type Token Ratio) (number of unique words / number of words)\n",
    "WikiLarge_Train_df['ttr'] = WikiLarge_Train_df['total_unique_words'] / WikiLarge_Train_df['total_words']\n",
    "WikiLarge_Train_df['ttr']\n",
    "\n",
    "# RTTR (root type token ratio)\n",
    "WikiLarge_Train_df['ttr'] = WikiLarge_Train_df['total_unique_words'] / np.sqrt(WikiLarge_Train_df['total_words'])\n",
    "\n",
    "# CTTR (corrected type token ratio)\n",
    "WikiLarge_Train_df['ttr'] = WikiLarge_Train_df['total_unique_words'] / np.sqrt(2 * WikiLarge_Train_df['total_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSTTR is the average TTR for each non-overlapping segment of equal size\n",
    "segment_size = 5\n",
    "\n",
    "def msttr_helper(lst:list, segment_size:int=segment_size):\n",
    "    segment_size = np.min(segment_size, len(lst))\n",
    "    lst = [x.lower() for x in lst]\n",
    "    segments = [lst[i*segment_size: i*segment_size + segment_size] for i in range(int(np.ceil(len(lst)/segment_size)))]\n",
    "    segment_ttr_vals = [len(set(x)) / segment_size for x in segments if len(x) == segment_size]\n",
    "    \n",
    "    return np.sum(segment_ttr_vals)/len(segment_ttr_vals)\n",
    "\n",
    "    \n",
    "# WikiLarge_Train_df['msttr'] = WikiLarge_Train_df['og_split'].apply(msttr_helper)\n",
    "WikiLarge_Train_df['og_split'].apply(msttr_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATTR is the average TTR for all possible overlapping segments of equal size. \n",
    "segment_size = 5\n",
    "\n",
    "def mattr_helper(lst:list, segment_size:int=segment_size):\n",
    "    segment_size = np.min(segment_size, len(lst))\n",
    "    lst = [x.lower() for x in lst]\n",
    "    segments = [lst[i: i + segment_size] for i in range(len(lst))]\n",
    "    segment_ttr_vals = [len(set(x)) / segment_size for x in segments if len(x) == segment_size]\n",
    "    \n",
    "    return np.sum(segment_ttr_vals)/len(segment_ttr_vals)\n",
    "\n",
    "# WikiLarge_Train_df['mattr'] = WikiLarge_Train_df['og_split'].apply(msttr_helper)\n",
    "WikiLarge_Train_df['og_split'].apply(mattr_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
